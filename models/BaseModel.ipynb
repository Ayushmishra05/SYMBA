{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model QED\n",
    "This is the base setup for working on QED data.\n",
    "It shows how to import the data and how to convert the expressions into different formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic\n",
    "import sympy as sp\n",
    "from itertools import (takewhile,repeat)\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import sys\n",
    "import importlib.util\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 17:53:13.632629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:53:13.636276: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-10-11 17:53:13.636408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:980] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = importlib.util.spec_from_file_location(\"SympyPrefix\", \"../sympy-prefix/source/SympyPrefix.py\")\n",
    "SympyPrefix = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"SympyPrefix\"] = SympyPrefix\n",
    "spec.loader.exec_module(SympyPrefix)\n",
    "prefix_to_sympy = SympyPrefix.prefix_to_sympy\n",
    "sympy_to_prefix = SympyPrefix.sympy_to_prefix\n",
    "sympy_to_hybrid_prefix = SympyPrefix.sympy_to_hybrid_prefix\n",
    "hybrid_prefix_to_sympy = SympyPrefix.hybrid_prefix_to_sympy\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"sp2tree\", \"../data-preprocessing/tree/sympy_to_tree.py\")\n",
    "sp2tree = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"SympyTree\"] = sp2tree\n",
    "spec.loader.exec_module(sp2tree)\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(\"symba_utilities\", \"../conversions.py\")\n",
    "symba_utilities = importlib.util.module_from_spec(spec)\n",
    "sys.modules[\"symba_utilities\"] = symba_utilities\n",
    "# spec.loader.exec_module(utilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def fix_i(expr_str):\n",
    "    reg_ex = \"[^a-z]i[^a-z,^\\d]\"\n",
    "    replaced = re.sub(reg_ex, fix_i_match, expr_str)\n",
    "    return replaced\n",
    "    \n",
    "def fix_i_match(matchobj):\n",
    "    \"\"\"\n",
    "    i --> I\n",
    "    \"\"\"\n",
    "    match = matchobj.group(0)\n",
    "    return match.replace(\"i\", \"I\")\n",
    "\n",
    "\n",
    "def rawincount(filename):\n",
    "    \"\"\"count numer of lines in a file. \n",
    "    From https://stackoverflow.com/questions/845058/how-to-get-line-count-of-a-large-file-cheaply-in-python\n",
    "    \"\"\"\n",
    "    f = open(filename, 'rb')\n",
    "    bufgen = takewhile(lambda x: x, (f.raw.read(1024*1024) for _ in repeat(None)))\n",
    "    return sum( buf.count(b'\\n') for buf in bufgen )\n",
    "\n",
    "def load_raw_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading raw amplitudes from filename.\n",
    "    \n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "    \"\"\"\n",
    "    print(\"Loading amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "        line = f.readline()\n",
    "        ctr = 0\n",
    "        data[ctr] = line.replace(\"\\n\", \"\")\n",
    "        while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                data[ctr] = line.replace(\"\\n\", \"\")\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_squared_amplitudes(filename, max_lines=-1):\n",
    "    \"\"\"\n",
    "    Loading squared amplitudes from filename and parsing into sympy.\n",
    "    All squared amplitudes should be exportet from sympy and thus be readable\n",
    "    without any preprocessing.\n",
    "\n",
    "    Options:\n",
    "        - `max_lines`: maximum number of lines to read\n",
    "\n",
    "    Returns:\n",
    "        list of squared amplitudes, each as a sympy expression\n",
    "    \"\"\"\n",
    "    print(\"Loading squared amplitudes from \"+ filename)\n",
    "    if max_lines > 0:\n",
    "        number_of_lines = max_lines\n",
    "    else:\n",
    "        number_of_lines = rawincount(filename)\n",
    "    data = [0 for i in range(number_of_lines-1)]\n",
    "    pbar = tqdm(total=number_of_lines)\n",
    "    with open(filename) as f:\n",
    "       line = f.readline()\n",
    "       line_sp = sp.sympify(line.strip())\n",
    "       ctr = 0\n",
    "       data[ctr] = line_sp\n",
    "       while line:\n",
    "            line = f.readline()\n",
    "            if line != \"\":\n",
    "                line = line.strip()\n",
    "                line = fix_i(line)\n",
    "                line_sp = sp.sympify(line.strip())\n",
    "                data[ctr] = line_sp\n",
    "            pbar.update(1)\n",
    "            ctr = ctr + 1\n",
    "            if ctr >= number_of_lines:\n",
    "                break\n",
    "    pbar.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_1to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d155bd331dbc4103aa080671d7b0b595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_1to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a21c058f89a4d8fa9cb9be4283c0a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_2to1.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d97d62bb42d4ba4b66d435525faf561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_2to1.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "778f52e5983540d7a084bb2e0e3ec130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/432 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_2to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fff9444f172447e84d3ed1cbf14e6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_2to2.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9960af1f1d554b7fae3eb428e79f4593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10944 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading amplitudes from ../raw_data.nosync/QED_amplitudes_TreeLevel_2to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91cf78e4e7b1464a981fa7e61e57e624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading squared amplitudes from ../raw_data.nosync/QED_sqamplitudes_TreeLevel_2to3.txt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2926be73f547b2891007be81c554bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/129024 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m sqampl_f \u001b[39m=\u001b[39m data_folder \u001b[39m+\u001b[39m sqamplitudes_filename_start \u001b[39m+\u001b[39m process \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m.txt\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m amplitudes_process \u001b[39m=\u001b[39m load_raw_amplitudes(ampl_f, max_lines\u001b[39m=\u001b[39mmax_lines)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m sqamplitudes_process \u001b[39m=\u001b[39m load_squared_amplitudes(sqampl_f, max_lines\u001b[39m=\u001b[39;49mmax_lines)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m amplitudes\u001b[39m.\u001b[39mappend(amplitudes_process)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m sqamplitudes\u001b[39m.\u001b[39mappend(sqamplitudes_process)\n",
      "\u001b[1;32m/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb Cell 6\u001b[0m in \u001b[0;36mload_squared_amplitudes\u001b[0;34m(filename, max_lines)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=79'>80</a>\u001b[0m     line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39mstrip()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=80'>81</a>\u001b[0m     line \u001b[39m=\u001b[39m fix_i(line)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=81'>82</a>\u001b[0m     line_sp \u001b[39m=\u001b[39m sp\u001b[39m.\u001b[39;49msympify(line\u001b[39m.\u001b[39;49mstrip())\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=82'>83</a>\u001b[0m     data[ctr] \u001b[39m=\u001b[39m line_sp\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#W5sZmlsZQ%3D%3D?line=83'>84</a>\u001b[0m pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sympy/core/sympify.py:495\u001b[0m, in \u001b[0;36msympify\u001b[0;34m(a, locals, convert_xor, strict, rational, evaluate)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     a \u001b[39m=\u001b[39m a\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 495\u001b[0m     expr \u001b[39m=\u001b[39m parse_expr(a, local_dict\u001b[39m=\u001b[39;49m\u001b[39mlocals\u001b[39;49m, transformations\u001b[39m=\u001b[39;49mtransformations, evaluate\u001b[39m=\u001b[39;49mevaluate)\n\u001b[1;32m    496\u001b[0m \u001b[39mexcept\u001b[39;00m (TokenError, \u001b[39mSyntaxError\u001b[39;00m) \u001b[39mas\u001b[39;00m exc:\n\u001b[1;32m    497\u001b[0m     \u001b[39mraise\u001b[39;00m SympifyError(\u001b[39m'\u001b[39m\u001b[39mcould not parse \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m%\u001b[39m a, exc)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sympy/parsing/sympy_parser.py:1096\u001b[0m, in \u001b[0;36mparse_expr\u001b[0;34m(s, local_dict, transformations, global_dict, evaluate)\u001b[0m\n\u001b[1;32m   1093\u001b[0m     code \u001b[39m=\u001b[39m \u001b[39mcompile\u001b[39m(evaluateFalse(code), \u001b[39m'\u001b[39m\u001b[39m<string>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39meval\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   1095\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1096\u001b[0m     rv \u001b[39m=\u001b[39m eval_expr(code, local_dict, global_dict)\n\u001b[1;32m   1097\u001b[0m     \u001b[39m# restore neutral definitions for names\u001b[39;00m\n\u001b[1;32m   1098\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m local_dict\u001b[39m.\u001b[39mpop(null, ()):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/sympy/parsing/sympy_parser.py:915\u001b[0m, in \u001b[0;36meval_expr\u001b[0;34m(code, local_dict, global_dict)\u001b[0m\n\u001b[1;32m    909\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_expr\u001b[39m(code, local_dict, global_dict):\n\u001b[1;32m    910\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    911\u001b[0m \u001b[39m    Evaluate Python code generated by ``stringify_expr``.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \n\u001b[1;32m    913\u001b[0m \u001b[39m    Generally, ``parse_expr`` should be used.\u001b[39;00m\n\u001b[1;32m    914\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 915\u001b[0m     expr \u001b[39m=\u001b[39m \u001b[39meval\u001b[39;49m(\n\u001b[1;32m    916\u001b[0m         code, global_dict, local_dict)  \u001b[39m# take local objects in preference\u001b[39;00m\n\u001b[1;32m    917\u001b[0m     \u001b[39mreturn\u001b[39;00m expr\n",
      "File \u001b[0;32m<string>:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data_folder = \"../raw_data.nosync/\"\n",
    "amplitudes_filename_start = \"QED_amplitudes_TreeLevel_\"\n",
    "sqamplitudes_filename_start = \"QED_sqamplitudes_TreeLevel_\"\n",
    "processes = [\"1to2\", \"2to1\", \"2to2\", \"2to3\", \"3to2\"]\n",
    "max_lines = -1\n",
    "\n",
    "amplitudes = []\n",
    "sqamplitudes = []\n",
    "for process in processes:\n",
    "    ampl_f = data_folder + amplitudes_filename_start + process + \".txt\"\n",
    "    sqampl_f = data_folder + sqamplitudes_filename_start + process + \".txt\"\n",
    "    amplitudes_process = load_raw_amplitudes(ampl_f, max_lines=max_lines)\n",
    "    sqamplitudes_process = load_squared_amplitudes(sqampl_f, max_lines=max_lines)\n",
    "    amplitudes.append(amplitudes_process)\n",
    "    sqamplitudes.append(sqamplitudes_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep the different amplitudes separated for now, so `amplitudes` has the form\n",
    "`[multiplicity, i]` where `multiplicity = [\"1to2\", \"2to1\", ...]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# the amplitudes are in prefix format\n",
    "print(len(amplitudes))\n",
    "print(len(sqamplitudes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Prod,-1,Prod,i,Prod,e,Prod,gamma,alpha_2,alpha_0,alpha_1,Prod,A^(*),i_2,alpha_2,(p_3),Prod,mu,i_0,alpha_1,(p_1)_u,mu^(*),i_1,alpha_0,(p_2)_u'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amplitudes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "$\\displaystyle - 4 e^{2} \\cdot \\left(2 m_{\\mu}^{2} - s_{12}\\right)$"
      ],
      "text/plain": [
       "-4*e**2*(2*m_mu**2 - s_12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqamplitudes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a77b7bbe604ee2894b81f431e7a4be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fecae42a7b884d319f05c7f1faadde42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ac05b6f49f4db982dc42691df27a81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array(['mul', 's-', '4', 'mul', 'pow', 'e', '2', 'add', 'mul', 's-', '1',\n",
       "       's_12', 'mul', '2', 'pow', 'm_mu', '2'], dtype='<U4')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert squared ampmlitudes to prefix\n",
    "ctr = 0\n",
    "def try_sympy_to_prefix(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        return sympy_to_prefix(expr)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_prefix = [[try_sympy_to_prefix(a) for a in tqdm(sq)] for sq in sqamplitudes]\n",
    "np.array(sqampl_prefix[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e58538db37f4d2a922dcc8beee7bca6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e73ba96e640dbb3f3ccb87527d5b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/431 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec29207107d4d08b71f3f99fd9a81fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10943 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/svg+xml": "<svg baseProfile=\"full\" height=\"264px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,856.0,264.0\" width=\"856px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"2.80374%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">4</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"1.40187%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"5.60748%\" x=\"2.80374%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">pow</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">e</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">4</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.60748%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"32.7103%\" x=\"8.41121%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">pow</text></svg><svg width=\"88.5714%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">add</text></svg><svg width=\"32.2581%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">reg_prop</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"16.129%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"32.2581%\" x=\"32.2581%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">s_23</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.3871%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"35.4839%\" x=\"64.5161%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"27.2727%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.6364%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.7273%\" x=\"27.2727%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">pow</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">m_e</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.6364%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.2581%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"44.2857%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"11.4286%\" x=\"88.5714%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"94.2857%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"24.7664%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.8785%\" x=\"41.1215%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">add</text></svg><svg width=\"17.4603%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"27.2727%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.6364%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"72.7273%\" x=\"27.2727%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">pow</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">m_e</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">4</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"63.6364%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.73016%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"19.0476%\" x=\"17.4603%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">s_12</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">s_34</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.9841%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"19.0476%\" x=\"36.5079%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">s_13</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">s_24</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.0317%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"44.4444%\" x=\"55.5556%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"28.5714%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">pow</text></svg><svg width=\"62.5%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">m_e</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"37.5%\" x=\"62.5%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.25%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.2857%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"71.4286%\" x=\"28.5714%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">add</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-1</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">s_14</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">mul</text></svg><svg width=\"40%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-1</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"20%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"60%\" x=\"40%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">s_23</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"70%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"64.2857%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"77.7778%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.5607%\" y1=\"1.2em\" y2=\"3em\" /></svg>",
      "text/plain": [
       "Tree('mul', [4, Tree('pow', [e, 4]), Tree('pow', [Tree('add', [reg_prop, Tree('mul', [-2, s_23]), Tree('mul', [2, Tree('pow', [m_e, 2])])]), -2]), Tree('add', [Tree('mul', [2, Tree('pow', [m_e, 4])]), Tree('mul', [s_12, s_34]), Tree('mul', [s_13, s_24]), Tree('mul', [Tree('pow', [m_e, 2]), Tree('add', [Tree('mul', [-1, s_14]), Tree('mul', [-1, s_23])])])])])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert squared amplitudes to trees:\n",
    "ctr = 0\n",
    "def try_sympy_to_tree(expr):\n",
    "    global ctr\n",
    "    ctr = ctr + 1\n",
    "    try:\n",
    "        return sp2tree.sympy_to_tree(expr)\n",
    "    except:\n",
    "        print(\"problem with:\", expr, \"at ctr =\", ctr)\n",
    "        return 0\n",
    "sqampl_tree = [[try_sympy_to_tree(a) for a in tqdm(sq)] for sq in sqamplitudes]\n",
    "sqampl_tree[2][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this base model we will be using prefix notation for the amplitudes and squared amplitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "X_val = []\n",
    "y_val = []\n",
    "X_tmp = []\n",
    "y_tmp = []\n",
    "for a, s in zip(amplitudes, sqampl_prefix):\n",
    "    X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "        a, s, test_size=0.1, random_state=42\n",
    "    )\n",
    "    X_train = X_train + X_train_i\n",
    "    X_tmp = X_tmp + X_test_i\n",
    "    y_train = y_train + y_train_i\n",
    "    y_tmp = y_tmp + y_test_i\n",
    "\n",
    "X_train_i, X_test_i, y_train_i, y_test_i = train_test_split(\n",
    "    X_tmp, y_tmp, test_size=0.5, random_state=42\n",
    ")\n",
    "X_val = X_val + X_train_i\n",
    "X_test = X_test + X_test_i\n",
    "y_val = y_val + y_train_i\n",
    "y_test = y_test + y_test_i\n",
    "\n",
    "del X_tmp, y_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10622\n",
      "10622\n",
      "591\n",
      "591\n",
      "592\n",
      "592\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_val))\n",
    "print(len(y_val))\n",
    "print(len(X_test))\n",
    "print(len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(x) for x in X_train], bins=100);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(y) for y in y_train], bins=100);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only use those X,y where both are at most `sequence_length` long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X okay: 0.805027301826398\n",
      "y okay: 1.0\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 500\n",
    "sequence_length = 350\n",
    "batch_size = 1\n",
    "\n",
    "X_train_idx_okay = np.where([len(x) < sequence_length for x in X_train])[0]\n",
    "y_train_idx_okay = np.where([len(y) < sequence_length for y in y_train])[0]\n",
    "X_val_idx_okay = np.where([len(x) < sequence_length for x in X_val])[0]\n",
    "y_val_idx_okay = np.where([len(x) < sequence_length for x in y_val])[0]\n",
    "X_test_idx_okay = np.where([len(x) < sequence_length for x in X_test])[0]\n",
    "y_test_idx_okay = np.where([len(x) < sequence_length for x in y_test])[0]\n",
    "\n",
    "\n",
    "train_idx_okay = np.intersect1d(X_train_idx_okay, y_train_idx_okay) \n",
    "val_idx_okay = np.intersect1d(X_val_idx_okay, y_val_idx_okay) \n",
    "test_idx_okay = np.intersect1d(X_test_idx_okay, y_test_idx_okay) \n",
    "print(\"X okay:\", len(X_train_idx_okay) / len(X_train))\n",
    "print(\"y okay:\", len(y_train_idx_okay) / len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_short = [X_train[i] for i in train_idx_okay]\n",
    "y_train_short = [y_train[i] for i in train_idx_okay]\n",
    "\n",
    "X_val_short = [X_val[i] for i in val_idx_okay]\n",
    "y_val_short = [y_val[i] for i in val_idx_okay]\n",
    "\n",
    "X_test_short = [X_test[i] for i in test_idx_okay]\n",
    "y_test_short = [y_test[i] for i in test_idx_okay]\n",
    "\n",
    "\n",
    "X_train_text = [\" \".join(x.split(',')) for x in X_train_short]\n",
    "y_train_text = [\" \".join(yy) for yy in y_train_short]\n",
    "\n",
    "X_val_text = [\" \".join(x.split(',')) for x in X_val_short]\n",
    "y_val_text = [\" \".join(yy) for yy in y_val_short]\n",
    "\n",
    "X_test_text = [\" \".join(x.split(',')) for x in X_test_short]\n",
    "y_test_text = [\" \".join(yy) for yy in y_test_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exists, loading\n",
      "Exists, loading\n",
      "Exists, loading\n"
     ]
    }
   ],
   "source": [
    "# reading to sympy takes quite long.\n",
    "# We're here caching the alreaday converted amplitudes\n",
    "X_train_cache_file = data_folder+\"X_train.pickle\"\n",
    "y_train_cache_file = data_folder+\"y_train.pickle\"\n",
    "X_val_cache_file = data_folder+\"X_val.pickle\"\n",
    "y_val_cache_file = data_folder+\"y_val.pickle\"\n",
    "X_test_cache_file = data_folder+\"X_test.pickle\"\n",
    "y_test_cache_file = data_folder+\"y_test.pickle\"\n",
    "\n",
    "if os.path.exists(X_train_cache_file) & os.path.exists(y_train_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_train_cache_file, \"rb\") as f:\n",
    "        X_train_text = pickle.load(f)\n",
    "    with open(X_train_cache_file, \"rb\") as f:\n",
    "        y_train_text = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_train_text, f)\n",
    "    with open(y_train_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_train_text, f)\n",
    "\n",
    "if os.path.exists(X_val_cache_file) & os.path.exists(y_val_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_val_cache_file, \"rb\") as f:\n",
    "        X_val_text = pickle.load(f)\n",
    "    with open(X_val_cache_file, \"rb\") as f:\n",
    "        y_val_text = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_val_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_val_text, f)\n",
    "    with open(y_val_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_val_text, f)\n",
    "\n",
    "if os.path.exists(X_test_cache_file) & os.path.exists(y_test_cache_file):\n",
    "    print(\"Exists, loading\")\n",
    "    with open(X_test_cache_file, \"rb\") as f:\n",
    "        X_test_text = pickle.load(f)\n",
    "    with open(X_test_cache_file, \"rb\") as f:\n",
    "        y_test_text = pickle.load(f)\n",
    "\n",
    "else:\n",
    "    with open(X_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(X_test_text, f)\n",
    "    with open(y_test_cache_file, \"wb\") as f:\n",
    "        pickle.dump(y_test_text, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_standardization(input_string):\n",
    "    return input_string\n",
    "\n",
    "X_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    "    standardize=None,\n",
    ")\n",
    "\n",
    "y_vectorization = TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length+1,\n",
    "    standardize=None,\n",
    ")\n",
    "\n",
    "X_vectorization.adapt(X_train_text)\n",
    "y_vectorization.adapt(y_train_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dataset(X, y):\n",
    "    X_vec = X_vectorization(X)\n",
    "    y_vec = y_vectorization(y)\n",
    "    return (\n",
    "        {\n",
    "            \"encoder_inputs\": X_vec,\n",
    "            \"decoder_inputs\": y_vec[:, :-1],\n",
    "        },\n",
    "        y_vec[:, 1:],\n",
    "    )\n",
    "\n",
    "\n",
    "def make_dataset(X_text, y_text):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X_text, y_text))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "\n",
    "train_ds = make_dataset(X_train_text, y_train_text)\n",
    "val_ds = make_dataset(X_val_text, y_val_text)\n",
    "test_ds = make_dataset(X_test_text, y_test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs[\"encoder_inputs\"].shape: (1, 350)\n",
      "inputs[\"decoder_inputs\"].shape: (1, 350)\n",
      "targets.shape: (1, 350)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-11 16:33:18.988240: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
    "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
    "    print(f\"targets.shape: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super(TransformerEncoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(dense_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, tf.newaxis, :], dtype=\"int32\")\n",
    "        attention_output = self.attention(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=padding_mask\n",
    "        )\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "\n",
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, vocab_size, embed_dim, **kwargs):\n",
    "        super(PositionalEmbedding, self).__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=vocab_size, output_dim=embed_dim\n",
    "        )\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=embed_dim\n",
    "        )\n",
    "        self.sequence_length = sequence_length\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "\n",
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, latent_dim, num_heads, **kwargs):\n",
    "        super(TransformerDecoder, self).__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim\n",
    "        )\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [\n",
    "                layers.Dense(latent_dim, activation=\"relu\"),\n",
    "                layers.Dense(embed_dim),\n",
    "            ]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs, value=inputs, key=inputs, attention_mask=causal_mask\n",
    "        )\n",
    "        out_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=out_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        out_2 = self.layernorm_2(out_1 + attention_output_2)\n",
    "\n",
    "        proj_output = self.dense_proj(out_2)\n",
    "        return self.layernorm_3(out_2 + proj_output)\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1), tf.constant([1, 1], dtype=tf.int32)],\n",
    "            axis=0,\n",
    "        )\n",
    "        return tf.tile(mask, mult)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding_2 (Positi  (None, None, 128)   108800      ['encoder_inputs[0][0]']         \n",
      " onalEmbedding)                                                                                   \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, None, 128)   791296      ['positional_embedding_2[0][0]'] \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, None, 500)    1492340     ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,392,436\n",
      "Trainable params: 2,392,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128 # 256  # 512\n",
    "latent_dim = 1024 #2048  # 16384\n",
    "num_heads = 8\n",
    "\n",
    "# with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"encoder_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, latent_dim, num_heads)(x)\n",
    "encoder = keras.Model(encoder_inputs, encoder_outputs)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int32\", name=\"decoder_inputs\")\n",
    "encoded_seq_inputs = keras.Input(shape=(None, embed_dim), name=\"decoder_state_inputs\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, latent_dim, num_heads)(x, encoded_seq_inputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "decoder = keras.Model([decoder_inputs, encoded_seq_inputs], decoder_outputs)\n",
    "\n",
    "decoder_outputs = decoder([decoder_inputs, encoder_outputs])\n",
    "transformer = keras.Model(\n",
    "    [encoder_inputs, decoder_inputs], decoder_outputs, name=\"transformer\"\n",
    ")\n",
    "transformer.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'learning rate')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def learning_rate_cyclic(epoch):\n",
    "    initial_lr = 0.0005\n",
    "    max_lr = 0.002\n",
    "    max_epochs = 5\n",
    "    if epoch <= (max_epochs / 2):\n",
    "        lr = initial_lr + (max_lr-initial_lr) * epoch/(max_epochs/2)\n",
    "        return lr\n",
    "    if (epoch > (max_epochs / 2)) & (epoch < max_epochs):\n",
    "        lr = max_lr - (max_lr-initial_lr) * (epoch-max_epochs/2)/(max_epochs/2)\n",
    "        return lr\n",
    "    else:\n",
    "        lr = initial_lr*np.exp(-(epoch-max_epochs)/10)\n",
    "        return lr\n",
    "\n",
    "xrange = range(0,50)\n",
    "yrange = [learning_rate_cyclic(x) for x in xrange]\n",
    "plt.plot(xrange, yrange)\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.ylabel(\"learning rate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"transformer\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding_2 (Positi  (None, None, 128)   108800      ['encoder_inputs[0][0]']         \n",
      " onalEmbedding)                                                                                   \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, None, 128)   791296      ['positional_embedding_2[0][0]'] \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, None, 500)    1492340     ['decoder_inputs[0][0]',         \n",
      "                                                                  'transformer_encoder_1[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,392,436\n",
      "Trainable params: 2,392,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/50\n",
      "8551/8551 [==============================] - 67s 8ms/step - loss: 0.0383 - accuracy: 0.9079 - val_loss: 0.0094 - val_accuracy: 0.9740 - lr: 5.0000e-04\n",
      "Epoch 2/50\n",
      "8551/8551 [==============================] - 65s 8ms/step - loss: 0.0245 - accuracy: 0.9400 - val_loss: 0.0169 - val_accuracy: 0.9629 - lr: 0.0011\n",
      "Epoch 3/50\n",
      "8551/8551 [==============================] - 66s 8ms/step - loss: 0.0506 - accuracy: 0.8669 - val_loss: 0.0424 - val_accuracy: 0.8862 - lr: 0.0017\n",
      "Epoch 4/50\n",
      "8551/8551 [==============================] - 66s 8ms/step - loss: 0.0433 - accuracy: 0.8877 - val_loss: 0.0419 - val_accuracy: 0.9029 - lr: 0.0017\n",
      "Epoch 5/50\n",
      "8551/8551 [==============================] - 67s 8ms/step - loss: 0.0268 - accuracy: 0.9270 - val_loss: 0.0220 - val_accuracy: 0.9398 - lr: 0.0011\n",
      "Epoch 6/50\n",
      "8551/8551 [==============================] - 67s 8ms/step - loss: 0.0118 - accuracy: 0.9670 - val_loss: 0.0077 - val_accuracy: 0.9791 - lr: 5.0000e-04\n",
      "Epoch 7/50\n",
      "6555/8551 [=====================>........] - ETA: 15s - loss: 0.0063 - accuracy: 0.9829"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#X33sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m transformer\u001b[39m.\u001b[39msummary()\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#X33sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m transformer\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#X33sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39madam\u001b[39m\u001b[39m\"\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msparse_categorical_crossentropy\u001b[39m\u001b[39m\"\u001b[39m, metrics\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#X33sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#X33sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m history \u001b[39m=\u001b[39m transformer\u001b[39m.\u001b[39;49mfit(train_ds, epochs\u001b[39m=\u001b[39;49mepochs, validation_data\u001b[39m=\u001b[39;49mval_ds,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/boggog/Documents/PhD-ML/GSoC/SYMBA/models/BaseModel.ipynb#X33sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m                           callbacks \u001b[39m=\u001b[39;49m callbacks)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/keras/engine/training.py:1564\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1556\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1557\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1558\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1561\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1562\u001b[0m ):\n\u001b[1;32m   1563\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1564\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1565\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1566\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2494\u001b[0m   (graph_function,\n\u001b[1;32m   2495\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2496\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2497\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1859\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1860\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1861\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1862\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1863\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1864\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1865\u001b[0m     args,\n\u001b[1;32m   1866\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1867\u001b[0m     executing_eagerly)\n\u001b[1;32m   1868\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    497\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    498\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 499\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    500\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    501\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    502\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    503\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    504\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    505\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    507\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    508\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    511\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    512\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50  # This should be at least 30 for convergence\n",
    "lr_schedule = tf.keras.callbacks.LearningRateScheduler(learning_rate_cyclic)\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(\n",
    "    \"models/2022-10-10-Transformer_2to2\", save_best_only=True, monitor=\"val_loss\", save_weights_only=True\n",
    ")\n",
    "\n",
    "callbacks = [lr_schedule]\n",
    "\n",
    "transformer.summary()\n",
    "transformer.compile(\n",
    "    \"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    ")\n",
    "history = transformer.fit(train_ds, epochs=epochs, validation_data=val_ds,\n",
    "                          callbacks = callbacks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4adc2ea131058d4ca334736eaf83f8a99f586a60b7e02773f5921bb39d3dbeb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
