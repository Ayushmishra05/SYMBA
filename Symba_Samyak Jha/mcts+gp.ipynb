{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-29T17:21:33.023998Z","iopub.status.busy":"2024-06-29T17:21:33.023293Z","iopub.status.idle":"2024-06-29T17:21:39.453346Z","shell.execute_reply":"2024-06-29T17:21:39.452385Z","shell.execute_reply.started":"2024-06-29T17:21:33.023951Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import sympy as sp\n","import signal\n","import time\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import r2_score\n","from collections import OrderedDict\n","from IPython.display import clear_output\n","import random\n","import operator\n","import math\n","import re\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn import Transformer\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from dataclasses import dataclass, field, fields\n","import os\n","from math import isclose, sqrt, log\n","from gym import spaces\n","from types import SimpleNamespace\n","from tqdm import tqdm\n","import pickle \n","import ast\n","seed = 42"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.455429Z","iopub.status.busy":"2024-06-29T17:21:39.455042Z","iopub.status.idle":"2024-06-29T17:21:39.481310Z","shell.execute_reply":"2024-06-29T17:21:39.480522Z","shell.execute_reply.started":"2024-06-29T17:21:39.455403Z"},"trusted":true},"outputs":[],"source":["device = 'cuda' if torch.cuda.is_available() else 'cpu'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.482765Z","iopub.status.busy":"2024-06-29T17:21:39.482495Z","iopub.status.idle":"2024-06-29T17:21:39.553695Z","shell.execute_reply":"2024-06-29T17:21:39.552861Z","shell.execute_reply.started":"2024-06-29T17:21:39.482741Z"},"trusted":true},"outputs":[],"source":["df_target = pd.read_csv('/kaggle/input/gsoc-symba-task/FeynmanEquations.csv')\n","df_target.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.556041Z","iopub.status.busy":"2024-06-29T17:21:39.555768Z","iopub.status.idle":"2024-06-29T17:21:39.591639Z","shell.execute_reply":"2024-06-29T17:21:39.590815Z","shell.execute_reply.started":"2024-06-29T17:21:39.556016Z"},"trusted":true},"outputs":[],"source":["df_target = df_target.dropna(subset=['Filename'])\n","df_target"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.592804Z","iopub.status.busy":"2024-06-29T17:21:39.592544Z","iopub.status.idle":"2024-06-29T17:21:39.603101Z","shell.execute_reply":"2024-06-29T17:21:39.602225Z","shell.execute_reply.started":"2024-06-29T17:21:39.592781Z"},"trusted":true},"outputs":[],"source":["df_target.loc[21, '# variables'] = 3\n","df_target.loc[22, '# variables'] = 4\n","df_target.loc[38, '# variables'] = 4\n","df_target.loc[82, '# variables'] = 3\n","df_target.loc[90, '# variables'] = 4\n","df_target.loc[98, '# variables'] = 5\n","df_target.loc[18,'Filename'] = 'I.15.10'\n","df_target.loc[49,'Filename'] = 'I.48.20'\n","df_target.loc[61,'Filename'] = 'II.11.7'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.604528Z","iopub.status.busy":"2024-06-29T17:21:39.604221Z","iopub.status.idle":"2024-06-29T17:21:39.611665Z","shell.execute_reply":"2024-06-29T17:21:39.610812Z","shell.execute_reply.started":"2024-06-29T17:21:39.604499Z"},"trusted":true},"outputs":[],"source":["variables = [\n","        'x',\n","        'y',\n","        'z',\n","        'a',\n","        'b',\n","        'c',\n","        'd',\n","        'E',\n","        'reg_prop',\n","        'm_s',\n","        'm_u'\n","        's_0',\n","        's_1',\n","        's_2',\n","        's_3',\n","        's_4',\n","        's_5',\n","        's_6',\n","        's_7',\n","        's_8',\n","        's_9',\n","        's_10',\n","        's_11',\n","        's_12',\n","        's_13',\n","        's_14',\n","        's_15',\n","        's_16',\n","        's_17',\n","        's_18',\n","        's_19',\n","        's_20',\n","        's_21',\n","        's_22',\n","        's_23',\n","        's_24',\n","        's_25',\n","        's_26',\n","        's_27',\n","        's_28',\n","        's_29',\n","        's_30',\n","        's_31',\n","        's_32',\n","        's_33',\n","        's_34',\n","        's_35',\n","        's_36',\n","        's_37',\n","        's_38',\n","        's_39',\n","        's_40',\n","        's_41',\n","        's_42',\n","        's_43',\n","        's_44',\n","        's_45',\n","        ]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.613616Z","iopub.status.busy":"2024-06-29T17:21:39.612906Z","iopub.status.idle":"2024-06-29T17:21:39.631923Z","shell.execute_reply":"2024-06-29T17:21:39.631120Z","shell.execute_reply.started":"2024-06-29T17:21:39.613591Z"},"trusted":true},"outputs":[],"source":["operators = {\n","    # Elementary functions\n","    sp.Add: 'add',\n","    sp.Mul: 'mul',\n","    sp.Pow: 'pow',\n","    sp.exp: 'exp',\n","    sp.log: 'ln',\n","    sp.Abs: 'abs',\n","    sp.sign: 'sign',\n","#     sp.Sub: 'sub',\n","#     sp.Div: 'div',\n","    # Trigonometric Functions\n","    sp.sin: 'sin',\n","    sp.cos: 'cos',\n","    sp.tan: 'tan',\n","    sp.cot: 'cot',\n","    sp.sec: 'sec',\n","    sp.csc: 'csc',\n","    # Trigonometric Inverses\n","    sp.asin: 'asin',\n","    sp.acos: 'acos',\n","    sp.atan: 'atan',\n","    sp.acot: 'acot',\n","    sp.asec: 'asec',\n","    sp.acsc: 'acsc',\n","    # Hyperbolic Functions\n","    sp.sinh: 'sinh',\n","    sp.cosh: 'cosh',\n","    sp.tanh: 'tanh',\n","    sp.coth: 'coth',\n","    sp.sech: 'sech',\n","    sp.csch: 'csch',\n","    # Hyperbolic Inverses\n","    sp.asinh: 'asinh',\n","    sp.acosh: 'acosh',\n","    sp.atanh: 'atanh',\n","    sp.acoth: 'acoth',\n","    sp.asech: 'asech',\n","    sp.acsch: 'acsch',\n","    sp.Min: 'min',\n","    # Derivative\n","    sp.Derivative: 'derivative',\n","}\n","\n","operators_inv = {operators[key]: key for key in operators}\n","operators_inv.update({'sub': lambda x, y: x - y,'div': lambda x, y: x / y})\n","operators_inv[\"mul(\"] = sp.Mul\n","operators_inv[\"add(\"] = sp.Add\n","\n","operators_nargs = {\n","    # Elementary functions\n","    'mul(': -1,\n","    'add(': -1,\n","    'add': 2,\n","    'sub': 2,\n","    'mul': 2,\n","    'div': 2,\n","    'pow': 2,\n","    'rac': 2,\n","    'inv': 1,\n","    'pow2': 1,\n","    'pow3': 1,\n","    'pow4': 1,\n","    'pow5': 1,\n","    'sqrt': 1,\n","    'exp': 1,\n","    'ln': 1,\n","    'abs': 1,\n","    'sign': 1,\n","    # Trigonometric Functions\n","    'sin': 1,\n","    'cos': 1,\n","    'tan': 1,\n","    'cot': 1,\n","    'sec': 1,\n","    'csc': 1,\n","    # Trigonometric Inverses\n","    'asin': 1,\n","    'acos': 1,\n","    'atan': 1,\n","    'acot': 1,\n","    'asec': 1,\n","    'acsc': 1,\n","    # Hyperbolic Functions\n","    'sinh': 1,\n","    'cosh': 1,\n","    'tanh': 1,\n","    'coth': 1,\n","    'sech': 1,\n","    'csch': 1,\n","    # Hyperbolic Inverses\n","    'asinh': 1,\n","    'acosh': 1,\n","    'atanh': 1,\n","    'acoth': 1,\n","    'asech': 1,\n","    'acsch': 1,\n","    # Derivative\n","    'derivative': 2,\n","    # custom functions\n","    'f': 1,\n","    'g': 2,\n","    'h': 3,\n","}\n","\n","masses_strings = [\n","        \"m_e\",\n","        \"m_u\",\n","        \"m_d\",\n","        \"m_s\",\n","        \"m_c\",\n","        \"m_b\",\n","        \"m_t\",\n","        ]\n","\n","masses = [sp.Symbol(x) for x in masses_strings]\n","\n","# these will be converted to the numbers format in `format_number`\n","integers_types = [\n","        sp.core.numbers.Integer,\n","        sp.core.numbers.One,\n","        sp.core.numbers.NegativeOne,\n","        sp.core.numbers.Zero,\n","        ]\n","\n","numbers_types = integers_types + [sp.core.numbers.Rational,\n","        sp.core.numbers.Half, sp.core.numbers.Exp1, sp.core.numbers.Pi, \"<class 'sympy.core.numbers.Pi'>\",\n","        sp.core.numbers.ImaginaryUnit]\n","\n","# don't continue evaluating at these, but stop\n","atoms = [\n","        str,\n","        sp.core.symbol.Symbol,\n","        sp.core.numbers.Exp1,\n","        sp.core.numbers.Pi,\n","        \"<class 'sympy.core.numbers.Pi'>\",\n","        ] + numbers_types\n","\n","\n","Inverse_trig = {\n","    'arcsin': 'asin',\n","    'arccos': 'acos',\n","    'arctan': 'atan',\n","    'arccot': 'acot',\n","    'arcsec': 'asec',\n","    'arccsc': 'acsc',\n","    'arcsinh': 'asinh',\n","    'arccosh': 'acosh',\n","    'arctanh': 'atanh',\n","    'arccoth': 'acoth',\n","    'arcsech': 'asech',\n","    'arccsch': 'acsch',         \n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.633597Z","iopub.status.busy":"2024-06-29T17:21:39.633313Z","iopub.status.idle":"2024-06-29T17:21:39.875359Z","shell.execute_reply":"2024-06-29T17:21:39.874527Z","shell.execute_reply.started":"2024-06-29T17:21:39.633573Z"},"trusted":true},"outputs":[],"source":["for i in range(len(df_target)):\n","    formula = df_target['Formula'][i]\n","    for a in Inverse_trig.keys():\n","        df_target.loc[i,'Formula'] = re.sub(a,Inverse_trig[a],formula)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.876708Z","iopub.status.busy":"2024-06-29T17:21:39.876424Z","iopub.status.idle":"2024-06-29T17:21:39.910039Z","shell.execute_reply":"2024-06-29T17:21:39.909208Z","shell.execute_reply.started":"2024-06-29T17:21:39.876685Z"},"trusted":true},"outputs":[],"source":["df_target"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.913408Z","iopub.status.busy":"2024-06-29T17:21:39.913174Z","iopub.status.idle":"2024-06-29T17:21:39.920095Z","shell.execute_reply":"2024-06-29T17:21:39.919252Z","shell.execute_reply.started":"2024-06-29T17:21:39.913387Z"},"trusted":true},"outputs":[],"source":["df_target.iloc[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.921411Z","iopub.status.busy":"2024-06-29T17:21:39.921118Z","iopub.status.idle":"2024-06-29T17:21:39.928249Z","shell.execute_reply":"2024-06-29T17:21:39.927418Z","shell.execute_reply.started":"2024-06-29T17:21:39.921387Z"},"trusted":true},"outputs":[],"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i : i + n]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.929515Z","iopub.status.busy":"2024-06-29T17:21:39.929233Z","iopub.status.idle":"2024-06-29T17:21:39.938398Z","shell.execute_reply":"2024-06-29T17:21:39.937544Z","shell.execute_reply.started":"2024-06-29T17:21:39.929461Z"},"trusted":true},"outputs":[],"source":["class Tokenizer:\n","    def __init__(self, vocab_path):\n","        self.vocab_path = vocab_path\n","        self.word2id = {}\n","        self.id2word = {}\n","\n","        with open(vocab_path) as file:\n","            words = map(lambda x: x.rstrip('\\n'), file.readlines())\n","\n","        for (n, word) in enumerate(words):\n","            self.word2id[word] = n\n","            self.id2word[n] = word \n","\n","    def encode(self, lst):\n","        return np.array([[self.word2id[j] for j in i] for i in lst], dtype=np.ushort)\n","\n","    def decode(self, lst):\n","        return [[self.id2word[j] for j in i] for i in lst]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.939703Z","iopub.status.busy":"2024-06-29T17:21:39.939407Z","iopub.status.idle":"2024-06-29T17:21:39.957653Z","shell.execute_reply":"2024-06-29T17:21:39.956698Z","shell.execute_reply.started":"2024-06-29T17:21:39.939680Z"},"trusted":true},"outputs":[],"source":["class Encoder_tokeniser(Tokenizer):\n","    def __init__(self,float_precision,mantissa_len,max_exponent,vocab_path,max_len = 10):\n","        super().__init__(vocab_path)\n","        \n","        self.max_len = max_len\n","        self.float_precision = float_precision\n","        self.mantissa_len = mantissa_len\n","        self.max_exponent = max_exponent\n","        self.base = (self.float_precision + 1) // self.mantissa_len\n","        self.max_token = 10 ** self.base\n","        \n","    def pre_tokenize(self, data):\n","        arr = np.array([i.split() for i in data], dtype=np.float32)\n","        permutation = [-1] + [i for i in range(arr.shape[1]-1)]\n","        arr = np.pad(arr[:, permutation], ((0,0), (0, self.max_len - arr.shape[1])), mode=\"constant\", constant_values=[-np.inf])\n","        return arr\n","    \n","    def tokenize(self, data):\n","        out = self.pre_tokenize(data)\n","        out = self.encode_float(out)\n","        out = self.encode(out)\n","        return out\n","        \n","    def encode_float(self,values):\n","        if len(values.shape) == 1:\n","            seq = []\n","            value = values\n","            for val in value:\n","                if val in [-np.inf, np.inf]:\n","                    seq.extend(['<pad>']*3)\n","                    continue\n","                \n","                sign = \"+\" if val >= 0 else \"-\"\n","                m, e = (f\"%.{self.float_precision}e\" % val).split(\"e\")\n","                i, f = m.lstrip(\"-\").split(\".\")\n","                i = i + f\n","                tokens = chunks(i, self.base)\n","                expon = int(e) - self.float_precision\n","                if expon < -self.max_exponent:\n","                    tokens = [\"0\" * self.base] * self.mantissa_len\n","                    expon = int(0)\n","                seq.extend([sign, *[\"N\" + token for token in tokens], \"E\" + str(expon)])\n","            return seq\n","        else:\n","            seqs = [self.encode_float(values[0])]\n","            N = values.shape[0]\n","            for n in range(1, N):\n","                seqs += [self.encode_float(values[n])]\n","        return seqs\n","    def decode_float(self,seq):\n","        if len(seq) == 0:\n","            return None\n","        decoded_seq = []\n","        for val in chunks(seq, 2 + self.mantissa_len):\n","            for x in val:\n","                if x[0] not in [\"-\", \"+\", \"E\", \"N\"]:\n","                    return np.nan\n","            try:\n","#                 print(val)\n","                sign = 1 if val[0] == \"+\" else -1\n","                mant = \"\"\n","                for x in val[1:-1]:\n","                    mant += x[1:]\n","                mant = int(mant)\n","#                 print(mant)\n","                exp = int(val[-1][1:])\n","#                 print(exp)\n","                value = sign * mant * (10 ** exp)\n","                value = float(value)\n","            except Exception:\n","                value = np.nan\n","            decoded_seq.append(value)\n","        return decoded_seq"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.959262Z","iopub.status.busy":"2024-06-29T17:21:39.958875Z","iopub.status.idle":"2024-06-29T17:21:39.971604Z","shell.execute_reply":"2024-06-29T17:21:39.970846Z","shell.execute_reply.started":"2024-06-29T17:21:39.959238Z"},"trusted":true},"outputs":[],"source":["def flatten(l, ltypes=(list, tuple)):\n","    \"\"\"\n","    flatten a python list\n","    from http://rightfootin.blogspot.com/2006/09/more-on-python-flatten.html\n","    \"\"\"\n","    ltype = type(l)\n","    l = list(l)\n","    i = 0\n","    while i < len(l):\n","        while isinstance(l[i], ltypes):\n","            if not l[i]:\n","                l.pop(i)\n","                i -= 1\n","                break\n","            else:\n","                l[i:i + 1] = l[i]\n","        i += 1\n","    return ltype(l)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.973448Z","iopub.status.busy":"2024-06-29T17:21:39.972895Z","iopub.status.idle":"2024-06-29T17:21:39.993567Z","shell.execute_reply":"2024-06-29T17:21:39.992599Z","shell.execute_reply.started":"2024-06-29T17:21:39.973417Z"},"trusted":true},"outputs":[],"source":["def sympy_to_prefix(expression):\n","    \"\"\"\n","    Recursively go from a sympy expression to a prefix notation.\n","    Returns a flat list of tokens.\n","    \"\"\"\n","    return flatten(sympy_to_prefix_rec(expression, []))\n","\n","def sympy_to_prefix_rec(expression, ret):\n","    \"\"\"\n","    Recursively go from a sympy expression to a prefix notation.\n","    The operators all get converted to their names in the array `operators`.\n","    Returns a nested list, where the nesting basically stands for parentheses.\n","    Since in prefix notation with a fixed number of arguments for each function (given in `operators_nargs`),\n","    parentheses are not needed, we can flatten the list later.\n","    \"\"\"\n","    if expression in [sp.core.numbers.Pi, sp.core.numbers.ImaginaryUnit]:\n","        f = expression\n","    else:\n","        f = expression.func\n","    if f in atoms:\n","        if type(expression) in numbers_types:\n","            return ret + format_number(expression)\n","        return ret+[str(expression)]\n","    f_str = operators[f]\n","    f_nargs = operators_nargs[f_str]\n","    args = expression.args\n","    if len(args) == 1 & f_nargs == 1:\n","        ret = ret + [f_str]\n","        return sympy_to_prefix_rec(args[0], ret)\n","    if len(args) == 2:\n","        ret = ret + [f_str, sympy_to_prefix_rec(args[0], []), sympy_to_prefix_rec(args[1], [])]\n","    if len(args) > 2:\n","        args = list(map(lambda x: sympy_to_prefix_rec(x, []), args))\n","        ret = ret + repeat_operator_until_correct_binary(f_str, args)\n","    return ret\n","def repeat_operator_until_correct_binary(op, args, ret=[]):\n","    \"\"\"\n","    sympy is not strict enough with the number of arguments.\n","    E.g. multiply takes a variable number of arguments, but for\n","    prefix notation it needs to ALWAYS have exactly 2 arguments\n","\n","    This function is only for binary operators.\n","\n","    Here I choose the convention as follows:\n","        1 + 2 + 3 --> + 1 + 2 3\n","\n","    This is the same convention as in https://arxiv.org/pdf/1912.01412.pdf\n","    on page 15.\n","\n","    input:\n","        op: in string form as in the list `operators`\n","        args: [arg1, arg2, ...] arguments of the operator, e.c. [1, 2, x**2,\n","                ...]. They can have other things to be evaluated in them\n","        ret: the list you already have. Usually []. Watch out, I think one has to explicitely give [],\n","            otherwise somehow the default value gets mutated, which I find a strange python behavior.\n","    \"\"\"\n","\n","    is_binary = operators_nargs[op] == 2\n","    assert is_binary, \"repeat_operator_until_correct_binary only takes binary operators\"\n","\n","    if len(args) == 0:\n","        return ret\n","    elif len(ret) == 0:\n","        ret = [op] + args[-2:]\n","        args = args[:-2]\n","    else:\n","        ret = [op] + args[-1:] + ret\n","        args = args[:-1]\n","\n","    return repeat_operator_until_correct_binary(op, args, ret)\n","\n","def format_number(number):\n","    if type(number) in integers_types:\n","        return format_integer(number)\n","    elif type(number) == sp.core.numbers.Rational:\n","        return format_rational(number)\n","    elif type(number) == sp.core.numbers.Half:\n","        return format_half()\n","    elif type(number) == sp.core.numbers.Exp1:\n","        return format_exp1()\n","    elif type(number) == sp.core.numbers.Pi:\n","        return format_pi()\n","    elif type(number) == sp.core.numbers.ImaginaryUnit:\n","        return format_imaginary_unit()\n","    else:\n","        raise NotImplementedError\n","\n","def format_exp1():\n","    return ['E']\n","\n","def format_pi():\n","    return ['pi']\n","\n","def format_imaginary_unit():\n","    return ['I']\n","\n","def format_half():\n","    \"\"\"\n","    for some reason in sympy 1/2 is its own object and not a rational.\n","    This function formats it correctly like `format_rational`\n","    \"\"\"\n","    return ['mul'] + ['s+', '1'] + ['pow'] + ['s+', '2'] + [\"s-\", \"1\"]\n","\n","def format_rational(number):\n","    # for some reason number.p is a string\n","    p = sp.sympify(number.p)\n","    q = sp.sympify(number.q)\n","    return ['mul'] + format_integer(p) + ['pow'] + format_integer(q) + ['s-', '1']\n","\n","def format_integer(integer):\n","    \"\"\"take a sympy integer and format it as in\n","    https://arxiv.org/pdf/1912.01412.pdf\n","\n","    input:\n","        integer: a `sympy.Integer` object, e.g. `sympy.Integer(-1)`\n","\n","    output:\n","        [sign_token, digit0, digit1, ...]\n","        where sign_token is 's+' or 's-'\n","\n","    Example:\n","        format_integer(sympy.Integer(-123))\n","        >> ['s-', '1', '2', '3']\n","\n","    Implementation notes:\n","    Somehow Integer inherits from Rational in Sympy and a rational is p/q,\n","    so integer.p is used to extract the number.\n","    \"\"\"\n","    # plus_sign = \"s+\"\n","    plus_sign = \"s+\"\n","    minus_sign = \"s-\"\n","    abs_num = abs(integer.p)\n","    is_neg = integer.could_extract_minus_sign()\n","    digits = list(str(abs_num))\n","    # digits = [str(abs_num)]\n","\n","    if is_neg:\n","        ret = [minus_sign] + digits\n","    else:\n","        ret = [plus_sign] + digits\n","\n","    return ret"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:39.994747Z","iopub.status.busy":"2024-06-29T17:21:39.994469Z","iopub.status.idle":"2024-06-29T17:21:40.007855Z","shell.execute_reply":"2024-06-29T17:21:40.006966Z","shell.execute_reply.started":"2024-06-29T17:21:39.994722Z"},"trusted":true},"outputs":[],"source":["def parse_if_str(x):\n","    if isinstance(x, str):\n","        return sp.parsing.parse_expr(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.009380Z","iopub.status.busy":"2024-06-29T17:21:40.009056Z","iopub.status.idle":"2024-06-29T17:21:40.018542Z","shell.execute_reply":"2024-06-29T17:21:40.017762Z","shell.execute_reply.started":"2024-06-29T17:21:40.009349Z"},"trusted":true},"outputs":[],"source":["def rightmost_string_pos(expr_arr, pos=-1):\n","    if isinstance(expr_arr[pos], str):\n","        return len(expr_arr)+pos\n","    else:\n","        return rightmost_string_pos(expr_arr, pos-1)\n","\n","\n","def rightmost_operand_pos(expr, pos):\n","    operators = list(operators_inv.keys()) + [\"s+\", \"s-\"] + variables\n","    if expr[pos] in operators:\n","        return pos\n","    else:\n","        return rightmost_operand_pos(expr, pos-1)\n","\n","def unformat_integer(arr):\n","    \"\"\"\n","    inverse of the function format_integer.\n","\n","    input:\n","        arr: array of strings just as the output of format_integer. E.g. [\"s+\", \"4\", \"2\"]\n","\n","    output:\n","        the correspinding sympy integer, e.g. sympy.Integer(42) in the above example.\n","\n","    The sign tokens are \"s+\" for positive integers and \"s-\" for negative. 0 comes with \"s+\", but does not matter.\n","\n","    \"\"\"\n","    sign_token = arr[0]\n","    ret = \"-\" if sign_token == \"s-\" else \"\"\n","    for s in arr[1:]:\n","        ret += str(s)\n","\n","    return sp.parsing.parse_expr(ret)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.019855Z","iopub.status.busy":"2024-06-29T17:21:40.019602Z","iopub.status.idle":"2024-06-29T17:21:40.033998Z","shell.execute_reply":"2024-06-29T17:21:40.033225Z","shell.execute_reply.started":"2024-06-29T17:21:40.019833Z"},"trusted":true},"outputs":[],"source":["def prefix_to_sympy(expr_arr):\n","    if len(expr_arr) == 1:\n","        return parse_if_str(expr_arr[0])\n","    op_pos = rightmost_operand_pos(expr_arr,len(expr_arr) - 1)\n","    if (op_pos == -1) | (op_pos == len(expr_arr) - 1 ):\n","        print(\"something went wrong, operator should not be at end of array\")\n","    op = expr_arr[op_pos]\n","    if op in operators_inv.keys():\n","        num_args = operators_nargs[op]\n","        op = operators_inv[op]\n","        args = expr_arr[op_pos+1:op_pos+num_args+1]\n","        args = [parse_if_str(a) for a in args]\n","#         print(op,*args)\n","        func = op(*args)\n","        expr = expr_arr[0:op_pos] + [func] + expr_arr[op_pos+num_args+1:]\n","        return prefix_to_sympy(expr)\n","\n","    elif (op == 's+') | (op == \"s-\"):\n","        # int_end_pos = rightmost_int_pos(expr_arr)\n","        string_end_pos = rightmost_string_pos(expr_arr)\n","        integer = unformat_integer(expr_arr[op_pos:string_end_pos+1])\n","        expr_arr_new = expr_arr[0:op_pos] + [integer] + expr_arr[string_end_pos+1:]\n","        return prefix_to_sympy(expr_arr_new)\n","    elif op in variables:\n","        op = sp.sympify(op)\n","        expr_arr_new = expr_arr[0:op_pos] + [op] + expr_arr[op_pos+1:]\n","        return prefix_to_sympy(expr_arr_new)\n","\n","    return op"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.035821Z","iopub.status.busy":"2024-06-29T17:21:40.035077Z","iopub.status.idle":"2024-06-29T17:21:40.047956Z","shell.execute_reply":"2024-06-29T17:21:40.047044Z","shell.execute_reply.started":"2024-06-29T17:21:40.035796Z"},"trusted":true},"outputs":[],"source":["class DecoderTokenizer(Tokenizer):\n","    def __init__(self, vocab_path):\n","        super().__init__(vocab_path)\n","\n","    def equation_encoder(self, data):\n","        return [sympy_to_prefix(expr) for expr in data]\n","    \n","    def equation_decoder(self, data):\n","        return [prefix_to_sympy(lst) for lst in data]\n","\n","    def pre_tokenize(self, data):\n","        return data\n","    \n","    def tokenize(self, data):\n","        out = self.pre_tokenize(data)\n","        out = self.equation_encoder(out)\n","        out = [['<bos>'] + i + ['<eos>'] for i in out]\n","        out = self.encode(out)\n","        return out\n","    \n","    def reverse_tokenize(self, data):\n","        out = self.decode(data)\n","        out = self.equation_decoder(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.049556Z","iopub.status.busy":"2024-06-29T17:21:40.049198Z","iopub.status.idle":"2024-06-29T17:21:40.057395Z","shell.execute_reply":"2024-06-29T17:21:40.056525Z","shell.execute_reply.started":"2024-06-29T17:21:40.049526Z"},"trusted":true},"outputs":[],"source":["INPUT_DIR = '/kaggle/input/gsoc-symba-task/Feynman_with_units/Feynman_with_units/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.060269Z","iopub.status.busy":"2024-06-29T17:21:40.059999Z","iopub.status.idle":"2024-06-29T17:21:40.070304Z","shell.execute_reply":"2024-06-29T17:21:40.069380Z","shell.execute_reply.started":"2024-06-29T17:21:40.060246Z"},"trusted":true},"outputs":[],"source":["class FeynmanDataset(Dataset):\n","    def __init__(self, df, dataset_dir):\n","        super().__init__()\n","        self.df = df\n","        self.dataset_dir = dataset_dir\n","        self.prefix_equations = np.load(os.path.join(dataset_dir, \"prefix_equations.npy\"))\n","        # prefix_equations = []\n","\n","        prefix_equations = []\n","        for prefix in self.prefix_equations:\n","            prefix_equations.append(np.trim_zeros(prefix))\n","\n","        self.prefix_equations = prefix_equations\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        path = os.path.join(os.path.join(self.dataset_dir, row['Filename']), f\"{row['data_num']}.npy\")\n","        x = np.load(path).astype(np.int32)\n","\n","        path = os.path.join(self.dataset_dir, f\"{row['Filename']}.npy\")\n","        y = self.prefix_equations[int(row['number']) - 1]\n","\n","        return (torch.Tensor(x).long(), torch.Tensor(y).long())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.071801Z","iopub.status.busy":"2024-06-29T17:21:40.071450Z","iopub.status.idle":"2024-06-29T17:21:40.084198Z","shell.execute_reply":"2024-06-29T17:21:40.083361Z","shell.execute_reply.started":"2024-06-29T17:21:40.071771Z"},"trusted":true},"outputs":[],"source":["def get_datasets(df, input_df, dataset_dir):\n","    train_df, test_df = train_test_split(df, test_size=0.1,random_state = 42)\n","    train_equations = train_df['Filename'].tolist()\n","    test_equations = test_df['Filename'].tolist()\n","\n","    input_test_df = input_df[input_df['Filename'].isin(test_equations)]\n","    input_train_df = input_df[input_df['Filename'].isin(train_equations)]\n","\n","    input_train_df, input_val_df = train_test_split(input_train_df, test_size = 0.1, shuffle=True)\n","\n","    train_dataset = FeynmanDataset(input_train_df, dataset_dir)\n","    val_dataset = FeynmanDataset(input_val_df, dataset_dir)\n","    test_dataset = FeynmanDataset(input_test_df, dataset_dir)\n","\n","    datasets = {\n","        \"train\":train_dataset,\n","        \"test\":test_dataset,\n","        \"valid\":val_dataset\n","        }\n","\n","    return datasets"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.085675Z","iopub.status.busy":"2024-06-29T17:21:40.085188Z","iopub.status.idle":"2024-06-29T17:21:40.094302Z","shell.execute_reply":"2024-06-29T17:21:40.093525Z","shell.execute_reply.started":"2024-06-29T17:21:40.085651Z"},"trusted":true},"outputs":[],"source":["class config:\n","    def __init__(self):\n","        self.input_max_len = 1000\n","        self.max_len = 11\n","        self.df_path = '/kaggle/input/gsoc-symba-task/FeynmanEquationsModified.csv'\n","        self.encoder_vocab = '/kaggle/input/gsoc-symba-task/encoder_vocab (1).txt'\n","        self.decoder_vocab = '/kaggle/input/gsoc-symba-task/decoder_vocab (2).txt'\n","        self.output_dir = '/kaggle/working/dataset_arrays'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.095623Z","iopub.status.busy":"2024-06-29T17:21:40.095348Z","iopub.status.idle":"2024-06-29T17:21:40.167400Z","shell.execute_reply":"2024-06-29T17:21:40.166445Z","shell.execute_reply.started":"2024-06-29T17:21:40.095599Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('/kaggle/input/gsoc-dataset-arrays/train_df.csv')\n","train_df.rename(columns = {'filename':'Filename'}, inplace = True)\n","train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.169064Z","iopub.status.busy":"2024-06-29T17:21:40.168794Z","iopub.status.idle":"2024-06-29T17:21:40.394387Z","shell.execute_reply":"2024-06-29T17:21:40.393530Z","shell.execute_reply.started":"2024-06-29T17:21:40.169041Z"},"trusted":true},"outputs":[],"source":["datasets = get_datasets(df_target,train_df,'/kaggle/input/gsoc-dataset-arrays/dataset_arrays/')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.396383Z","iopub.status.busy":"2024-06-29T17:21:40.396114Z","iopub.status.idle":"2024-06-29T17:21:40.428278Z","shell.execute_reply":"2024-06-29T17:21:40.427398Z","shell.execute_reply.started":"2024-06-29T17:21:40.396359Z"},"trusted":true},"outputs":[],"source":["class TokenEmbedding(nn.Module):\n","    ''' helper Module to convert tensor of input indices into corresponding tensor of token embeddings'''\n","    \n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","class PositionalEncoding(nn.Module):\n","    ''' helper Module that adds positional encoding to the token embedding to introduce a notion of word order.'''\n","    \n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        self.pos_embedding = torch.zeros((maxlen, emb_size))\n","        self.pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        self.pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        self.pos_embedding = self.pos_embedding.unsqueeze(0)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding_1', self.pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","#         print(token_embedding.shape)\n","        token_embedding = token_embedding.to('cuda:0')\n","        self.pos_embedding = self.pos_embedding.to('cuda:0')\n","#         token_embedding = token_embedding\n","#         self.pos_embedding = self.pos_embedding\n","        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n","\n","    \n","class LinearPointEmbedder(nn.Module):\n","    def __init__(self, vocab_size: int, input_emb_size, emb_size, max_input_points,dropout =0.2):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, input_emb_size)\n","        self.emb_size = emb_size\n","        self.input_size = max_input_points*input_emb_size\n","        self.fc1 = nn.Linear(self.input_size, emb_size)\n","        self.fc2 = nn.Linear(emb_size, emb_size)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tokens):\n","        out = self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","        bs, n = out.shape[0], out.shape[1]\n","        out = out.view(bs, n, -1)\n","        out = self.activation(self.fc1(out))\n","        out = self.dropout(out)\n","        out = self.fc2(out)\n","        return out\n","    \n","\n","class Model_seq2seq(nn.Module):\n","    '''Seq2Seq Network'''\n","    \n","    def __init__(self,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 emb_size: int,\n","                 nhead: int,\n","                 src_vocab_size: int,\n","                 tgt_vocab_size: int,\n","                 input_emb_size: int,\n","                 max_input_points: int,\n","                 dim_feedforward: int = 512,\n","                 dropout: float = 0.1,):\n","        super(Model_seq2seq, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout,\n","                                       batch_first=True)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = LinearPointEmbedder(src_vocab_size, input_emb_size, emb_size, max_input_points)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n","\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.src_tok_emb(src)\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.src_tok_emb(src), src_mask)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)\n","    \n","    def beam_search(self, src: Tensor, src_mask: Tensor, src_padding_mask: Tensor, beam_size: int = 3, max_len: int = 65,start_state = None):\n","        # Encode the source sequence\n","        memory = self.encode(src, src_mask)\n","        \n","        # Initialize the decoder input with the <sos> token (assuming 0 is the <sos> token)\n","        batch_size = src.size(0)\n","        if start_state == None:\n","            start_symbol = 1  # Modify according to your tokenization scheme\n","\n","            # Beam search variables\n","            beam = [(torch.tensor([[start_symbol]], device=device), 0)]  # (sequence, score)\n","        else:\n","            beam = [(torch.tensor(start_state,device = device), 0)]\n","        completed_sequences = []\n","\n","        for _ in range(max_len):\n","            candidates = []\n","            for seq, score in beam:\n","                if seq[0, -1].item() == 58:  # Assuming 1 is the <eos> token\n","                    completed_sequences.append((seq, score))\n","                    continue\n","                \n","                # Decode the current sequence\n","                tgt_mask = (torch.triu(torch.ones((seq.size(1), seq.size(1)), device=device))).transpose(0, 1)\n","                tgt_mask = tgt_mask.float().masked_fill(tgt_mask == 0, float('-inf')).masked_fill(tgt_mask == 1, float(0.0))\n","                tgt_emb = self.positional_encoding(self.tgt_tok_emb(seq))\n","                out = self.transformer.decoder(tgt_emb, memory, tgt_mask)\n","                logits = self.generator(out[:, -1, :])\n","                log_probs = torch.log_softmax(logits, dim=-1)\n","\n","                # Get the top beam_size candidates\n","                top_log_probs, top_indices = torch.topk(log_probs, beam_size)\n","                for i in range(beam_size):\n","                    new_seq = torch.cat([seq, top_indices[:, i].unsqueeze(1)], dim=1)\n","                    new_score = score + top_log_probs[:, i].item()\n","                    candidates.append((new_seq, new_score))\n","\n","            # Sort candidates by score and select the top beam_size sequences\n","            candidates = sorted(candidates, key=lambda x: x[1], reverse=True)\n","            beam = candidates[:beam_size]\n","\n","        # If no sequence ended with <eos>, return the best candidate\n","        if not completed_sequences:\n","            completed_sequences = beam\n","\n","        # Sort completed sequences by score and return the best one\n","        completed_sequences = sorted(completed_sequences, key=lambda x: x[1], reverse=True)\n","#         best_sequence, best_score = completed_sequences[0]\n","\n","        return completed_sequences[:3]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.429737Z","iopub.status.busy":"2024-06-29T17:21:40.429420Z","iopub.status.idle":"2024-06-29T17:21:40.441185Z","shell.execute_reply":"2024-06-29T17:21:40.440419Z","shell.execute_reply.started":"2024-06-29T17:21:40.429695Z"},"trusted":true},"outputs":[],"source":["config = config()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.446624Z","iopub.status.busy":"2024-06-29T17:21:40.446347Z","iopub.status.idle":"2024-06-29T17:21:40.462099Z","shell.execute_reply":"2024-06-29T17:21:40.461233Z","shell.execute_reply.started":"2024-06-29T17:21:40.446601Z"},"trusted":true},"outputs":[],"source":["encoder_tokenizer = Encoder_tokeniser(2,1,100,config.encoder_vocab)\n","decoder_tokenizer = DecoderTokenizer(config.decoder_vocab)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.463513Z","iopub.status.busy":"2024-06-29T17:21:40.463229Z","iopub.status.idle":"2024-06-29T17:21:40.469784Z","shell.execute_reply":"2024-06-29T17:21:40.468940Z","shell.execute_reply.started":"2024-06-29T17:21:40.463462Z"},"trusted":true},"outputs":[],"source":["def convert_to_functional_form(expr):\n","    # Ensure the input is a SymPy expression\n","    expr = sp.sympify(expr)\n","    for key,value in operators.items():\n","        if isinstance(expr, key):\n","            args = expr.args\n","            return f\"{value}({', '.join(convert_to_functional_form(arg) for arg in args)})\"\n","    for item in numbers_types:\n","        if type(expr) == item:\n","            return str(expr)\n","    if isinstance(expr, sp.Symbol):\n","        return str(expr)\n","    else:\n","        print(expr)\n","        raise ValueError(f\"Unsupported expression type: {type(expr)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:21:40.471067Z","iopub.status.busy":"2024-06-29T17:21:40.470819Z","iopub.status.idle":"2024-06-29T17:21:40.482415Z","shell.execute_reply":"2024-06-29T17:21:40.481619Z","shell.execute_reply.started":"2024-06-29T17:21:40.471044Z"},"trusted":true},"outputs":[],"source":["class DecisionNode:\n","    def __init__(self, parent, state, possible_actions, is_terminal=False):\n","        self.parent = parent\n","        self.state = state\n","        self.possible_actions = possible_actions\n","        self.is_terminal = is_terminal\n","        self.children = []\n","        self.visits = 0\n","        self.value = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:27:41.055634Z","iopub.status.busy":"2024-06-29T17:27:41.055231Z","iopub.status.idle":"2024-06-29T17:27:41.086429Z","shell.execute_reply":"2024-06-29T17:27:41.085509Z","shell.execute_reply.started":"2024-06-29T17:27:41.055602Z"},"trusted":true},"outputs":[],"source":["class MCTS:\n","    def __init__(self, model,points,rollouts=100, kmax=5, beam_size=3, c=1.4, max_length=50, penalty=-1, lam=0.1,beta = 1):\n","        self.model = model\n","        self.points = points \n","        self.rollouts = rollouts\n","        self.kmax = kmax\n","        self.beam_size = beam_size\n","        self.c = c\n","        self.max_length = max_length\n","        self.penalty = penalty\n","        self.lam = lam\n","        self.reward_dict = {}\n","        self.beta = beta\n","\n","    def search(self, src, src_mask):\n","        root = DecisionNode(None, torch.tensor([[1]], device=device), possible_actions=list(range(self.model.tgt_tok_emb.embedding.num_embeddings)), is_terminal=False)\n","        for _ in range(self.rollouts):\n","            self.rollout(root, src, src_mask)\n","        best_seq = max(self.reward_dict,key = lambda k: self.reward_dict[k])\n","        return ast.literal_eval(best_seq)\n","\n","    def rollout(self, node, src, src_mask):\n","        path = [node]\n","        while len(node.children) > 0:\n","            node = self.select(node,src,src_mask)\n","            path.append(node)\n","        if not node.is_terminal:\n","            print(node.state)\n","            self.expand(node, src, src_mask)\n","        reward = self.evaluate(node, src, src_mask)\n","        self.backpropagate(path, reward)\n","\n","    def select(self, node,src,src_mask):\n","        N_parent = node.visits + 1  # Ensure non-zero\n","        values = []\n","        for child in node.children:\n","            Q_value = child.value / (child.visits + 1e-4)\n","            P_value = self.get_prior_probability(node, child, src, src_mask)\n","            PUCB_value = Q_value + self.beta * P_value * sqrt(log(N_parent) / (1 + child.visits))\n","            values.append(PUCB_value)\n","        return node.children[np.argmax(values)]\n","\n","    def get_prior_probability(self, parent, child, src, src_mask):\n","        # Assuming the prior probability P(a|s) can be obtained from model logits\n","        tgt_emb = self.model.positional_encoding(self.model.tgt_tok_emb(parent.state))\n","        memory = self.model.encode(src, src_mask)  # Use src and src_mask here\n","        out = self.model.transformer.decoder(tgt_emb, memory)\n","        logits = self.model.generator(out[:, -1, :])\n","        probabilities = torch.softmax(logits, dim=-1)\n","        action = child.state[0, -1].item()  # The action taken to reach this child\n","        return probabilities[0, action].item()\n","\n","    def expand(self, node, src, src_mask):\n","        tgt_emb = self.model.positional_encoding(self.model.tgt_tok_emb(node.state))\n","        memory = self.model.encode((src), src_mask)\n","        out = self.model.transformer.decoder(tgt_emb, memory)\n","        logits = self.model.generator(out[:, -1, :])\n","        top_k_indices = torch.topk(logits, self.kmax, dim=-1).indices.squeeze().tolist()\n","        \n","        for action in top_k_indices:\n","            next_state = torch.cat((node.state, torch.tensor([[action]], device=node.state.device)), dim=1)\n","            child_node = DecisionNode(node, next_state, node.possible_actions, is_terminal=(action == 58))\n","            node.children.append(child_node)\n","\n","    def evaluate(self, node, src, src_mask):\n","        src_padding_mask = (torch.zeros((src.shape[0], src.shape[1]),device = device)).type(torch.bool)\n","        generated_seqs = self.model.beam_search(src, src_mask, src_padding_mask=src_padding_mask, \n","                                                beam_size=self.beam_size, max_len=self.max_length,start_state=node.state)\n","        best_seq = generated_seqs[0]\n","        \n","        try :\n","            best_expr = (decoder_tokenizer.equation_decoder([decoder_tokenizer.decode(np.array(best_seq[0].to('cpu')))[0][1:-1]])[0])\n","        except :\n","            self.reward_dict[str((best_seq[0].cpu().numpy().tolist()))] = -1.0\n","            return -1.0\n","        y_pred = []\n","\n","        for i in range(self.points.shape[0]):\n","            sub = {}\n","            for j in range(1,self.points.shape[1]):\n","                sub[sp.Symbol(f's_{j}')] = self.points[i][j]\n","            result = best_expr.subs(sub)\n","            y_pred.append(result.evalf())\n","        try :\n","            y_pred = np.array(y_pred,dtype = 'float32')\n","        except :\n","            return -1.0\n","        y = np.array(self.points[:,0],dtype = 'float32')\n","        generations_tree = (best_seq[0].cpu().numpy().tolist()) \n","        reward = self.get_reward(y, y_pred, generations_tree)\n","        self.reward_dict[str((best_seq[0].cpu().numpy().tolist()))] = reward\n","        return reward\n","\n","    def get_reward(self, y, y_pred, generations_tree):\n","        eps = 1e-9\n","        NMSE = np.sqrt(np.mean((y - y_pred)**2) / (np.mean(y**2) + eps))\n","        print(\"NMSE\",NMSE)\n","\n","        if not np.isnan(NMSE):\n","            reward = ((1 / (NMSE + 1e-7)))\n","        else:\n","            reward = self.penalty\n","\n","        if generations_tree:\n","            complexity = len(generations_tree)\n","            reward += self.lam * np.exp(-complexity / 200)\n","\n","        return reward\n","\n","    def backpropagate(self, path, reward):\n","        for node in reversed(path):\n","            node.visits += 1\n","            node.value += reward"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:27:41.545797Z","iopub.status.busy":"2024-06-29T17:27:41.544908Z","iopub.status.idle":"2024-06-29T17:27:41.551207Z","shell.execute_reply":"2024-06-29T17:27:41.550124Z","shell.execute_reply.started":"2024-06-29T17:27:41.545762Z"},"trusted":true},"outputs":[],"source":["random.seed(seed)\n","os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = True"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-29T17:27:41.584792Z","iopub.status.busy":"2024-06-29T17:27:41.584284Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["random_numbers = [random.randint(0, 999) for _ in range(50)]\n","seed_expr = []\n","model = Model_seq2seq(num_encoder_layers=2,\n","              num_decoder_layers=6,\n","              emb_size=64,\n","              nhead=8,\n","              src_vocab_size=1104,\n","              tgt_vocab_size=59,\n","              input_emb_size=64,\n","              max_input_points=33,\n","              )\n","path = '/kaggle/input/gsoc-symba-seq2seq/default/best_checkpoint.pth'\n","model.load_state_dict(torch.load(path)[\"state_dict\"])\n","model = model.to(device)\n","for k in tqdm(random_numbers):\n","    a = encoder_tokenizer.decode(np.array(datasets['test'][8000 + k][0]))\n","    l1 = []\n","    for i in range(len(a)):\n","        l2 = []\n","        temp = -1\n","        for j in range(len(a[i])):\n","            if a[i][j] == '<pad>':\n","                temp = j\n","                break\n","        num_var = len(a[i][:temp])//3\n","#         print(num_var)\n","        for j in range(0,temp,3):\n","            l2.append(*encoder_tokenizer.decode_float(a[i][j:j+3]))\n","        l1.append(l2)\n","    points = np.array(l1)\n","    src = torch.tensor(np.array(datasets['test'][8000 + k][0]).reshape(1,1000,33)).to(device)\n","    src_mask = torch.zeros((src.shape[1], src.shape[1]), device=device).type(torch.bool)\n","    mcts = MCTS(model,points,rollouts=30, kmax=3, beam_size=3, c=1, max_length=65, penalty=-1, lam=0.01,beta = 0.25)\n","    generated_sequence = mcts.search(src, src_mask)\n","    try :    \n","        b = (decoder_tokenizer.equation_decoder([decoder_tokenizer.decode(np.array(generated_sequence))[0][1:-1]])[0])\n","        b = (convert_to_functional_form(b))\n","    #             print(b)\n","        seed_expr.append(b)\n","    except:\n","        continue"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["with open('/kaggle/input/gsoc-symba-task/Feynman_with_units/Feynman_with_units/II.35.21') as file:\n","    data = file.readlines()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["arr = np.array([i.split() for i in data], dtype=np.float32)\n","\n","points = []\n","for i in arr:\n","    count = 0\n","    temp = []\n","    for j in i[0:-1]:\n","        count += 1\n","        temp.append(j)\n","    points.append((temp,i[-1]))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["points"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["protected = {\n","    'exp':'protected_exp',\n","    'div':'protected_div',\n","    'sqrt':'protected_sqrt',\n","    'pow' : 'protected_pow'\n","}\n","\n","protected_inv = {\n","    value : key for key,value in protected.items()\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["protected_inv"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["for i in range(len(seed_expr)):\n","    for a in protected:\n","        seed_expr[i] = re.sub(a,protected[a],seed_expr[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["(seed_expr)[0]"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def logabs(x1):\n","    if x1 == 0:\n","        return 1\n","    return math.log(abs(x1))\n","\n","def n3(x1):\n","    return x1 ** 3\n","\n","def n4(x1):\n","    return x1 ** 4\n","\n","def protected_div(x1, x2):\n","    try:\n","        return x1 / x2 if abs(x2) > 0.001 else 1.\n","    except ZeroDivisionError:\n","        return 1.\n","\n","def protected_exp(x1):\n","    try:\n","        return math.exp(x1) if x1 < 100 else 0.0\n","    except OverflowError:\n","        return 0.0\n","\n","def protected_log(x1):\n","    try:\n","        return math.log(abs(x1)) if abs(x1) > 0.001 else 0.\n","    except ValueError:\n","        return 0.\n","\n","def protected_sqrt(x1):\n","    return math.sqrt(abs(x1))\n","\n","def protected_inv(x1):\n","    try:\n","        return 1. / x1 if abs(x1) > 0.001 else 0.\n","    except ZeroDivisionError:\n","        return 0.\n","\n","def protected_expneg(x1):\n","    try:\n","        return math.exp(-x1) if x1 > -100 else 0.0\n","    except OverflowError:\n","        return 0.0\n","\n","def protected_n2(x1):\n","    return x1 ** 2 if abs(x1) < 1e6 else 0.0\n","\n","def protected_n3(x1):\n","    return x1 ** 3 if abs(x1) < 1e6 else 0.0\n","\n","def protected_n4(x1):\n","    return x1 ** 4 if abs(x1) < 1e6 else 0.0\n","\n","def protected_pow(x1,x2):\n","    try:\n","        a = math.pow(x1,x2)\n","        return a\n","    except:\n","        return 1e7\n","\n","def protected_sigmoid(x1):\n","    return 1 / (1 + protected_expneg(x1))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def make_pset(num_var):\n","    pset = gp.PrimitiveSet(\"MAIN\", num_var)  # Assuming a single input variable, adjust as needed\n","\n","    # Add unprotected primitive operations\n","    pset.addPrimitive(operator.add, 2)\n","    pset.addPrimitive(operator.sub, 2)\n","    pset.addPrimitive(operator.mul, 2)\n","    # Do not add the unprotected division, use protected one instead\n","\n","    pset.addPrimitive(math.sin, 1)\n","    pset.addPrimitive(math.cos, 1)\n","    pset.addPrimitive(math.tan, 1)\n","    # Do not add the unprotected exp and log, use protected ones instead\n","    # Do not add the unprotected sqrt, use protected one instead\n","    pset.addPrimitive(operator.neg, 1)\n","    pset.addPrimitive(abs, 1)\n","    pset.addPrimitive(max, 2)\n","    pset.addPrimitive(min, 2)\n","    pset.addPrimitive(math.tanh, 1)\n","    \n","    for i in range(1,11):\n","        pset.addTerminal(i)\n","\n","    # Add protected primitive operations\n","    pset.addPrimitive(protected_div, 2)\n","    pset.addPrimitive(protected_pow, 2)\n","    pset.addPrimitive(protected_exp, 1)\n","    pset.addPrimitive(protected_log, 1)\n","    pset.addPrimitive(protected_sqrt, 1)\n","    pset.addTerminal(math.pi, name=\"pi\")\n","    \n","    rename_kwargs = {\"ARG{}\".format(i): f\"s_{i+1}\" for i in range(0,num_var)}\n","    \n","    pset.renameArguments(**rename_kwargs)\n","    \n","    return pset "]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from deap import base, creator, tools, gp, algorithms\n","import numpy as np\n","from fractions import Fraction\n","\n","\n","# Define a new fitness class for minimizing (weight=-1.0)\n","creator.create(\"FitnessMin\", base.Fitness, weights=(-1.0,))\n","creator.create(\"Individual\", gp.PrimitiveTree, fitness=creator.FitnessMin)\n","\n","# Create the DEAP PrimitiveSet\n","pset = make_pset(5)\n","# pset.addEphemeralConstant(\"rand101\", lambda: random.randint(-1,1))\n","\n","    # Define evaluation function\n","def evalSymbReg(individual, points):\n","    i = 0\n","    func = toolbox.compile(expr=individual)\n","    \n","    sqerrors = ((((func(*x) - y)**2)/len(points)) for x, y in points)\n","\n","    return math.fsum(sqerrors),\n","\n","def e_lexicase_selection(individuals, k, points):\n","    selected = []\n","    for _ in range(k):\n","        remaining = individuals[:]\n","        random.shuffle(points)  # Shuffle the test cases\n","        for point in points:\n","            errors = [abs(evalSymbReg(ind, [point])[0]) for ind in remaining]\n","            min_error = min(errors)\n","            remaining = [ind for ind, error in zip(remaining, errors) if error == min_error]\n","            if len(remaining) == 1:\n","                break\n","        selected.append(random.choice(remaining))\n","    return selected\n","\n","    # Seed population with predefined solutions\n","def seed_population(pop_size,seed_exprs):\n","    population = []\n","    count = 0\n","    for expr in seed_exprs:\n","        try :\n","            ind = creator.Individual.from_string(expr, pset)\n","            count += 1\n","            population.append(ind)\n","        except :\n","            continue\n","    print(len(seed_exprs),count)       \n","    for _ in range(pop_size - count):\n","        ind = toolbox.individual()\n","        population.append(ind)\n","    return population\n","\n","# Register functions with toolbox\n","toolbox = base.Toolbox()\n","toolbox.register(\"expr\", gp.genHalfAndHalf, pset=pset, min_=1, max_=2)\n","toolbox.register(\"individual\", tools.initIterate, creator.Individual, toolbox.expr)\n","toolbox.register(\"population\", seed_population)\n","toolbox.register(\"compile\", gp.compile, pset=pset)\n","toolbox.register(\"evaluate\", evalSymbReg, points=points)\n","toolbox.register(\"select\", lambda individuals, k: e_lexicase_selection(individuals, k, points)) \n","toolbox.register(\"mate\", gp.cxOnePoint)\n","toolbox.register(\"mutate\", gp.mutUniform, expr=toolbox.expr, pset=pset)\n","toolbox.register(\"map\", map)\n","\n","def main():\n","    random.seed(42)\n","    pop_size = 60\n","    pop = toolbox.population(pop_size=pop_size, seed_exprs=seed_expr)\n","\n","    # Evaluate the entire population\n","    for ind in pop:\n","        ind.fitness.values = toolbox.evaluate(ind)\n","\n","    hof = tools.HallOfFame(1)\n","    stats = tools.Statistics(lambda ind: ind.fitness.values)\n","    stats.register(\"avg\", np.mean)\n","    stats.register(\"std\", np.std)\n","    stats.register(\"min\", np.min)\n","    stats.register(\"max\", np.max)\n","\n","    ngen = 20\n","    mu, lambda_ = 300, 600 \n","    cxpb, mutpb = 0.5, 0.2\n","\n","    # Use the eaSimple algorithm\n","    pop, log = algorithms.eaSimple(pop, toolbox, cxpb, mutpb, ngen, stats=stats, halloffame=hof, verbose=True)\n","    return pop, stats, hof\n","\n","pop, stats, hof = main()\n","print(\"Best individual:\", hof[0])\n","print(\"Fitness:\", hof[0].fitness.values)\n","TSS = 0.0\n","mean_y = 0.0\n","count = 0\n","for _ , y in points:\n","    mean_y += y\n","    count += 1\n","mean_y /= count\n","for _ , y in points:\n","    TSS += (y - mean_y)**2\n","print(\"R2_score\",float(hof[0].fitness.values[0])/TSS)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":4610731,"sourceId":8530806,"sourceType":"datasetVersion"},{"datasetId":4655603,"sourceId":8534736,"sourceType":"datasetVersion"},{"datasetId":4660212,"sourceId":8674808,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
