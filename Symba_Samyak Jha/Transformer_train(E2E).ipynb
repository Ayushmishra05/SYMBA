{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-27T22:44:02.747571Z","iopub.status.busy":"2024-05-27T22:44:02.747245Z","iopub.status.idle":"2024-05-27T22:44:11.542639Z","shell.execute_reply":"2024-05-27T22:44:11.541693Z","shell.execute_reply.started":"2024-05-27T22:44:02.747542Z"},"trusted":true},"outputs":[],"source":["import sympy as sp\n","from sympy import *\n","import pandas as pd\n","import re\n","import pandas as pd\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn import Transformer\n","import math\n","import os\n","import random\n","import torch\n","from tqdm import tqdm\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","from dataclasses import dataclass, field, fields\n","from typing import Optional\n","from transformers import LEDForConditionalGeneration,LEDConfig"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.544952Z","iopub.status.busy":"2024-05-27T22:44:11.544510Z","iopub.status.idle":"2024-05-27T22:44:11.550219Z","shell.execute_reply":"2024-05-27T22:44:11.549021Z","shell.execute_reply.started":"2024-05-27T22:44:11.544926Z"},"trusted":true},"outputs":[],"source":["def chunks(lst, n):\n","    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n","    for i in range(0, len(lst), n):\n","        yield lst[i : i + n]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.555234Z","iopub.status.busy":"2024-05-27T22:44:11.554973Z","iopub.status.idle":"2024-05-27T22:44:11.563270Z","shell.execute_reply":"2024-05-27T22:44:11.562379Z","shell.execute_reply.started":"2024-05-27T22:44:11.555212Z"},"trusted":true},"outputs":[],"source":["class Tokenizer:\n","    def __init__(self, vocab_path):\n","        self.vocab_path = vocab_path\n","        self.word2id = {}\n","        self.id2word = {}\n","\n","        with open(vocab_path) as file:\n","            words = map(lambda x: x.rstrip('\\n'), file.readlines())\n","\n","        for (n, word) in enumerate(words):\n","            self.word2id[word] = n\n","            self.id2word[n] = word \n","\n","    def encode(self, lst):\n","        return np.array([[self.word2id[j] for j in i] for i in lst], dtype=np.ushort)\n","\n","    def decode(self, lst):\n","        return [[self.id2word[j] for j in i] for i in lst]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.564831Z","iopub.status.busy":"2024-05-27T22:44:11.564451Z","iopub.status.idle":"2024-05-27T22:44:11.581943Z","shell.execute_reply":"2024-05-27T22:44:11.581088Z","shell.execute_reply.started":"2024-05-27T22:44:11.564809Z"},"trusted":true},"outputs":[],"source":["class Encoder_tokeniser(Tokenizer):\n","    def __init__(self,float_precision,mantissa_len,max_exponent,vocab_path,max_len = 10):\n","        super().__init__(vocab_path)\n","        \n","        self.max_len = max_len\n","        self.float_precision = float_precision\n","        self.mantissa_len = mantissa_len\n","        self.max_exponent = max_exponent\n","        self.base = (self.float_precision + 1) // self.mantissa_len\n","        self.max_token = 10 ** self.base\n","        \n","    def pre_tokenize(self, data):\n","        arr = np.array([i.split() for i in data], dtype=np.float32)\n","        permutation = [-1] + [i for i in range(arr.shape[1]-1)]\n","        arr = np.pad(arr[:, permutation], ((0,0), (0, self.max_len - arr.shape[1])), mode=\"constant\", constant_values=[-np.inf])\n","        return arr\n","    \n","    def tokenize(self, data):\n","        out = self.pre_tokenize(data)\n","        out = self.encode_float(out)\n","        out = self.encode(out)\n","        return out\n","        \n","    def encode_float(self,values):\n","        if len(values.shape) == 1:\n","            seq = []\n","            value = values\n","            for val in value:\n","                if val in [-np.inf, np.inf]:\n","                    seq.extend(['<pad>']*3)\n","                    continue\n","                \n","                sign = \"+\" if val >= 0 else \"-\"\n","                m, e = (f\"%.{self.float_precision}e\" % val).split(\"e\")\n","                i, f = m.lstrip(\"-\").split(\".\")\n","                i = i + f\n","                tokens = chunks(i, self.base)\n","                expon = int(e) - self.float_precision\n","                if expon < -self.max_exponent:\n","                    tokens = [\"0\" * self.base] * self.mantissa_len\n","                    expon = int(0)\n","                seq.extend([sign, *[\"N\" + token for token in tokens], \"E\" + str(expon)])\n","            return seq\n","        else:\n","            seqs = [self.encode_float(values[0])]\n","            N = values.shape[0]\n","            for n in range(1, N):\n","                seqs += [self.encode_float(values[n])]\n","        return seqs\n","    def decode_float(self,seq):\n","        decoded_seq = []\n","        for val in chunks(decoded_seq, 2 + self.mantissa_len):\n","            for x in val:\n","                if x[0] not in [\"-\", \"+\", \"E\", \"N\"]:\n","                    return np.nan\n","            try:\n","                sign = 1 if val[0] == \"+\" else -1\n","                mant = \"\"\n","                for x in val[1:-1]:\n","                    mant += x[1:]\n","                mant = int(mant)\n","                exp = int(val[-1][1:])\n","                value = sign * mant * (10 ** exp)\n","                value = float(value)\n","            except Exception:\n","                value = np.nan\n","            decoded_seq.append(value)\n","        return decoded_seq"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.583266Z","iopub.status.busy":"2024-05-27T22:44:11.582997Z","iopub.status.idle":"2024-05-27T22:44:11.610058Z","shell.execute_reply":"2024-05-27T22:44:11.609116Z","shell.execute_reply.started":"2024-05-27T22:44:11.583244Z"},"trusted":true},"outputs":[],"source":["df_target = pd.read_csv('/kaggle/input/gsoc-symba-task/FeynmanEquations.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.611562Z","iopub.status.busy":"2024-05-27T22:44:11.611242Z","iopub.status.idle":"2024-05-27T22:44:11.656257Z","shell.execute_reply":"2024-05-27T22:44:11.655505Z","shell.execute_reply.started":"2024-05-27T22:44:11.611534Z"},"trusted":true},"outputs":[],"source":["df_target"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.657393Z","iopub.status.busy":"2024-05-27T22:44:11.657164Z","iopub.status.idle":"2024-05-27T22:44:11.693503Z","shell.execute_reply":"2024-05-27T22:44:11.692752Z","shell.execute_reply.started":"2024-05-27T22:44:11.657373Z"},"trusted":true},"outputs":[],"source":["df_target = df_target.dropna(subset=['Filename'])\n","df_target"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.694980Z","iopub.status.busy":"2024-05-27T22:44:11.694640Z","iopub.status.idle":"2024-05-27T22:44:11.706166Z","shell.execute_reply":"2024-05-27T22:44:11.705355Z","shell.execute_reply.started":"2024-05-27T22:44:11.694950Z"},"trusted":true},"outputs":[],"source":["df_target.loc[21, '# variables'] = 3\n","df_target.loc[22, '# variables'] = 4\n","df_target.loc[38, '# variables'] = 4\n","df_target.loc[82, '# variables'] = 3\n","df_target.loc[90, '# variables'] = 4\n","df_target.loc[98, '# variables'] = 5\n","df_target.loc[18,'Filename'] = 'I.15.10'\n","df_target.loc[49,'Filename'] = 'I.48.20'\n","df_target.loc[61,'Filename'] = 'II.11.7'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.724163Z","iopub.status.busy":"2024-05-27T22:44:11.723879Z","iopub.status.idle":"2024-05-27T22:44:11.731223Z","shell.execute_reply":"2024-05-27T22:44:11.730263Z","shell.execute_reply.started":"2024-05-27T22:44:11.724140Z"},"trusted":true},"outputs":[],"source":["variables = [\n","        'x',\n","        'y',\n","        'z',\n","        'a',\n","        'b',\n","        'c',\n","        'd',\n","        'E',\n","        'reg_prop',\n","        'm_s',\n","        'm_u'\n","        's_0',\n","        's_1',\n","        's_2',\n","        's_3',\n","        's_4',\n","        's_5',\n","        's_6',\n","        's_7',\n","        's_8',\n","        's_9',\n","        's_10',\n","        's_11',\n","        's_12',\n","        's_13',\n","        's_14',\n","        's_15',\n","        's_16',\n","        's_17',\n","        's_18',\n","        's_19',\n","        's_20',\n","        's_21',\n","        's_22',\n","        's_23',\n","        's_24',\n","        's_25',\n","        's_26',\n","        's_27',\n","        's_28',\n","        's_29',\n","        's_30',\n","        's_31',\n","        's_32',\n","        's_33',\n","        's_34',\n","        's_35',\n","        's_36',\n","        's_37',\n","        's_38',\n","        's_39',\n","        's_40',\n","        's_41',\n","        's_42',\n","        's_43',\n","        's_44',\n","        's_45',\n","        ]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.732495Z","iopub.status.busy":"2024-05-27T22:44:11.732268Z","iopub.status.idle":"2024-05-27T22:44:11.750521Z","shell.execute_reply":"2024-05-27T22:44:11.749664Z","shell.execute_reply.started":"2024-05-27T22:44:11.732475Z"},"trusted":true},"outputs":[],"source":["operators = {\n","    # Elementary functions\n","    sp.Add: 'add',\n","    sp.Mul: 'mul',\n","    sp.Pow: 'pow',\n","    sp.exp: 'exp',\n","    sp.log: 'ln',\n","    sp.Abs: 'abs',\n","    sp.sign: 'sign',\n","    # Trigonometric Functions\n","    sp.sin: 'sin',\n","    sp.cos: 'cos',\n","    sp.tan: 'tan',\n","    sp.cot: 'cot',\n","    sp.sec: 'sec',\n","    sp.csc: 'csc',\n","    # Trigonometric Inverses\n","    sp.asin: 'asin',\n","    sp.acos: 'acos',\n","    sp.atan: 'atan',\n","    sp.acot: 'acot',\n","    sp.asec: 'asec',\n","    sp.acsc: 'acsc',\n","    # Hyperbolic Functions\n","    sp.sinh: 'sinh',\n","    sp.cosh: 'cosh',\n","    sp.tanh: 'tanh',\n","    sp.coth: 'coth',\n","    sp.sech: 'sech',\n","    sp.csch: 'csch',\n","    # Hyperbolic Inverses\n","    sp.asinh: 'asinh',\n","    sp.acosh: 'acosh',\n","    sp.atanh: 'atanh',\n","    sp.acoth: 'acoth',\n","    sp.asech: 'asech',\n","    sp.acsch: 'acsch',\n","    # Derivative\n","    sp.Derivative: 'derivative',\n","}\n","\n","operators_inv = {operators[key]: key for key in operators}\n","operators_inv[\"mul(\"] = sp.Mul\n","operators_inv[\"add(\"] = sp.Add\n","\n","operators_nargs = {\n","    # Elementary functions\n","    'mul(': -1,\n","    'add(': -1,\n","    'add': 2,\n","    'sub': 2,\n","    'mul': 2,\n","    'div': 2,\n","    'pow': 2,\n","    'rac': 2,\n","    'inv': 1,\n","    'pow2': 1,\n","    'pow3': 1,\n","    'pow4': 1,\n","    'pow5': 1,\n","    'sqrt': 1,\n","    'exp': 1,\n","    'ln': 1,\n","    'abs': 1,\n","    'sign': 1,\n","    # Trigonometric Functions\n","    'sin': 1,\n","    'cos': 1,\n","    'tan': 1,\n","    'cot': 1,\n","    'sec': 1,\n","    'csc': 1,\n","    # Trigonometric Inverses\n","    'asin': 1,\n","    'acos': 1,\n","    'atan': 1,\n","    'acot': 1,\n","    'asec': 1,\n","    'acsc': 1,\n","    # Hyperbolic Functions\n","    'sinh': 1,\n","    'cosh': 1,\n","    'tanh': 1,\n","    'coth': 1,\n","    'sech': 1,\n","    'csch': 1,\n","    # Hyperbolic Inverses\n","    'asinh': 1,\n","    'acosh': 1,\n","    'atanh': 1,\n","    'acoth': 1,\n","    'asech': 1,\n","    'acsch': 1,\n","    # Derivative\n","    'derivative': 2,\n","    # custom functions\n","    'f': 1,\n","    'g': 2,\n","    'h': 3,\n","}\n","\n","masses_strings = [\n","        \"m_e\",\n","        \"m_u\",\n","        \"m_d\",\n","        \"m_s\",\n","        \"m_c\",\n","        \"m_b\",\n","        \"m_t\",\n","        ]\n","\n","masses = [sp.Symbol(x) for x in masses_strings]\n","\n","# these will be converted to the numbers format in `format_number`\n","integers_types = [\n","        sp.core.numbers.Integer,\n","        sp.core.numbers.One,\n","        sp.core.numbers.NegativeOne,\n","        sp.core.numbers.Zero,\n","        ]\n","\n","numbers_types = integers_types + [sp.core.numbers.Rational,\n","        sp.core.numbers.Half, sp.core.numbers.Exp1, sp.core.numbers.Pi, \"<class 'sympy.core.numbers.Pi'>\",\n","        sp.core.numbers.ImaginaryUnit]\n","\n","# don't continue evaluating at these, but stop\n","atoms = [\n","        str,\n","        sp.core.symbol.Symbol,\n","        sp.core.numbers.Exp1,\n","        sp.core.numbers.Pi,\n","        \"<class 'sympy.core.numbers.Pi'>\",\n","        ] + numbers_types\n","\n","\n","Inverse_trig = {\n","    'arcsin': 'asin',\n","    'arccos': 'acos',\n","    'arctan': 'atan',\n","    'arccot': 'acot',\n","    'arcsec': 'asec',\n","    'arccsc': 'acsc',\n","    'arcsinh': 'asinh',\n","    'arccosh': 'acosh',\n","    'arctanh': 'atanh',\n","    'arccoth': 'acoth',\n","    'arcsech': 'asech',\n","    'arccsch': 'acsch',         \n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.752076Z","iopub.status.busy":"2024-05-27T22:44:11.751521Z","iopub.status.idle":"2024-05-27T22:44:11.761938Z","shell.execute_reply":"2024-05-27T22:44:11.761144Z","shell.execute_reply.started":"2024-05-27T22:44:11.752045Z"},"trusted":true},"outputs":[],"source":["def sympy_expression(formula):\n","    # create a map of variables\n","    variables_map = {key : sp.Symbol(key) for key in variables}\n","\n","    for a in Inverse_trig.keys():\n","        formula = re.sub(a,Inverse_trig[a],formula)\n","\n","    # Convert to sympy expression\n","    return sp.sympify(formula, locals=variables_map)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.763100Z","iopub.status.busy":"2024-05-27T22:44:11.762848Z","iopub.status.idle":"2024-05-27T22:44:11.771434Z","shell.execute_reply":"2024-05-27T22:44:11.770617Z","shell.execute_reply.started":"2024-05-27T22:44:11.763079Z"},"trusted":true},"outputs":[],"source":["def flatten(l, ltypes=(list, tuple)):\n","    \"\"\"\n","    flatten a python list\n","    from http://rightfootin.blogspot.com/2006/09/more-on-python-flatten.html\n","    \"\"\"\n","    ltype = type(l)\n","    l = list(l)\n","    i = 0\n","    while i < len(l):\n","        while isinstance(l[i], ltypes):\n","            if not l[i]:\n","                l.pop(i)\n","                i -= 1\n","                break\n","            else:\n","                l[i:i + 1] = l[i]\n","        i += 1\n","    return ltype(l)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.772817Z","iopub.status.busy":"2024-05-27T22:44:11.772536Z","iopub.status.idle":"2024-05-27T22:44:11.792374Z","shell.execute_reply":"2024-05-27T22:44:11.791429Z","shell.execute_reply.started":"2024-05-27T22:44:11.772795Z"},"trusted":true},"outputs":[],"source":["def sympy_to_prefix(expression):\n","    \"\"\"\n","    Recursively go from a sympy expression to a prefix notation.\n","    Returns a flat list of tokens.\n","    \"\"\"\n","    return flatten(sympy_to_prefix_rec(expression, []))\n","\n","def sympy_to_prefix_rec(expression, ret):\n","    \"\"\"\n","    Recursively go from a sympy expression to a prefix notation.\n","    The operators all get converted to their names in the array `operators`.\n","    Returns a nested list, where the nesting basically stands for parentheses.\n","    Since in prefix notation with a fixed number of arguments for each function (given in `operators_nargs`),\n","    parentheses are not needed, we can flatten the list later.\n","    \"\"\"\n","    if expression in [sp.core.numbers.Pi, sp.core.numbers.ImaginaryUnit]:\n","        f = expression\n","    else:\n","        f = expression.func\n","    if f in atoms:\n","        if type(expression) in numbers_types:\n","            return ret + format_number(expression)\n","        return ret+[str(expression)]\n","    f_str = operators[f]\n","    f_nargs = operators_nargs[f_str]\n","    args = expression.args\n","    if len(args) == 1 & f_nargs == 1:\n","        ret = ret + [f_str]\n","        return sympy_to_prefix_rec(args[0], ret)\n","    if len(args) == 2:\n","        ret = ret + [f_str, sympy_to_prefix_rec(args[0], []), sympy_to_prefix_rec(args[1], [])]\n","    if len(args) > 2:\n","        args = list(map(lambda x: sympy_to_prefix_rec(x, []), args))\n","        ret = ret + repeat_operator_until_correct_binary(f_str, args)\n","    return ret\n","def repeat_operator_until_correct_binary(op, args, ret=[]):\n","    \"\"\"\n","    sympy is not strict enough with the number of arguments.\n","    E.g. multiply takes a variable number of arguments, but for\n","    prefix notation it needs to ALWAYS have exactly 2 arguments\n","\n","    This function is only for binary operators.\n","\n","    Here I choose the convention as follows:\n","        1 + 2 + 3 --> + 1 + 2 3\n","\n","    This is the same convention as in https://arxiv.org/pdf/1912.01412.pdf\n","    on page 15.\n","\n","    input:\n","        op: in string form as in the list `operators`\n","        args: [arg1, arg2, ...] arguments of the operator, e.c. [1, 2, x**2,\n","                ...]. They can have other things to be evaluated in them\n","        ret: the list you already have. Usually []. Watch out, I think one has to explicitely give [],\n","            otherwise somehow the default value gets mutated, which I find a strange python behavior.\n","    \"\"\"\n","\n","    is_binary = operators_nargs[op] == 2\n","    assert is_binary, \"repeat_operator_until_correct_binary only takes binary operators\"\n","\n","    if len(args) == 0:\n","        return ret\n","    elif len(ret) == 0:\n","        ret = [op] + args[-2:]\n","        args = args[:-2]\n","    else:\n","        ret = [op] + args[-1:] + ret\n","        args = args[:-1]\n","\n","    return repeat_operator_until_correct_binary(op, args, ret)\n","\n","def format_number(number):\n","    if type(number) in integers_types:\n","        return format_integer(number)\n","    elif type(number) == sp.core.numbers.Rational:\n","        return format_rational(number)\n","    elif type(number) == sp.core.numbers.Half:\n","        return format_half()\n","    elif type(number) == sp.core.numbers.Exp1:\n","        return format_exp1()\n","    elif type(number) == sp.core.numbers.Pi:\n","        return format_pi()\n","    elif type(number) == sp.core.numbers.ImaginaryUnit:\n","        return format_imaginary_unit()\n","    else:\n","        raise NotImplementedError\n","\n","def format_exp1():\n","    return ['E']\n","\n","def format_pi():\n","    return ['pi']\n","\n","def format_imaginary_unit():\n","    return ['I']\n","\n","def format_half():\n","    \"\"\"\n","    for some reason in sympy 1/2 is its own object and not a rational.\n","    This function formats it correctly like `format_rational`\n","    \"\"\"\n","    return ['mul'] + ['s+', '1'] + ['pow'] + ['s+', '2'] + [\"s-\", \"1\"]\n","\n","def format_rational(number):\n","    # for some reason number.p is a string\n","    p = sp.sympify(number.p)\n","    q = sp.sympify(number.q)\n","    return ['mul'] + format_integer(p) + ['pow'] + format_integer(q) + ['s-', '1']\n","\n","def format_integer(integer):\n","    \"\"\"take a sympy integer and format it as in\n","    https://arxiv.org/pdf/1912.01412.pdf\n","\n","    input:\n","        integer: a `sympy.Integer` object, e.g. `sympy.Integer(-1)`\n","\n","    output:\n","        [sign_token, digit0, digit1, ...]\n","        where sign_token is 's+' or 's-'\n","\n","    Example:\n","        format_integer(sympy.Integer(-123))\n","        >> ['s-', '1', '2', '3']\n","\n","    Implementation notes:\n","    Somehow Integer inherits from Rational in Sympy and a rational is p/q,\n","    so integer.p is used to extract the number.\n","    \"\"\"\n","    # plus_sign = \"s+\"\n","    plus_sign = \"s+\"\n","    minus_sign = \"s-\"\n","    abs_num = abs(integer.p)\n","    is_neg = integer.could_extract_minus_sign()\n","    digits = list(str(abs_num))\n","    # digits = [str(abs_num)]\n","\n","    if is_neg:\n","        ret = [minus_sign] + digits\n","    else:\n","        ret = [plus_sign] + digits\n","\n","    return ret"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.793742Z","iopub.status.busy":"2024-05-27T22:44:11.793457Z","iopub.status.idle":"2024-05-27T22:44:11.803660Z","shell.execute_reply":"2024-05-27T22:44:11.802860Z","shell.execute_reply.started":"2024-05-27T22:44:11.793711Z"},"trusted":true},"outputs":[],"source":["def parse_if_str(x):\n","    if isinstance(x, str):\n","        return sp.parsing.parse_expr(x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.804926Z","iopub.status.busy":"2024-05-27T22:44:11.804636Z","iopub.status.idle":"2024-05-27T22:44:11.814366Z","shell.execute_reply":"2024-05-27T22:44:11.813464Z","shell.execute_reply.started":"2024-05-27T22:44:11.804904Z"},"trusted":true},"outputs":[],"source":["def rightmost_string_pos(expr_arr, pos=-1):\n","    if isinstance(expr_arr[pos], str):\n","        return len(expr_arr)+pos\n","    else:\n","        return rightmost_string_pos(expr_arr, pos-1)\n","\n","\n","def rightmost_operand_pos(expr, pos=-1):\n","    operators = list(operators_inv.keys()) + [\"s+\", \"s-\"] + variables\n","    if expr[pos] in operators:\n","        return len(expr) + pos\n","    else:\n","        return rightmost_operand_pos(expr, pos-1)\n","\n","def unformat_integer(arr):\n","    \"\"\"\n","    inverse of the function format_integer.\n","\n","    input:\n","        arr: array of strings just as the output of format_integer. E.g. [\"s+\", \"4\", \"2\"]\n","\n","    output:\n","        the correspinding sympy integer, e.g. sympy.Integer(42) in the above example.\n","\n","    The sign tokens are \"s+\" for positive integers and \"s-\" for negative. 0 comes with \"s+\", but does not matter.\n","\n","    \"\"\"\n","    sign_token = arr[0]\n","    ret = \"-\" if sign_token == \"s-\" else \"\"\n","    for s in arr[1:]:\n","        ret += str(s)\n","\n","    return sp.parsing.parse_expr(ret)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.815820Z","iopub.status.busy":"2024-05-27T22:44:11.815485Z","iopub.status.idle":"2024-05-27T22:44:11.825782Z","shell.execute_reply":"2024-05-27T22:44:11.824835Z","shell.execute_reply.started":"2024-05-27T22:44:11.815791Z"},"trusted":true},"outputs":[],"source":["def prefix_to_sympy(expr_arr):\n","    if len(expr_arr) == 1:\n","        return parse_if_str(expr_arr[0])\n","    op_pos = rightmost_operand_pos(expr_arr)\n","    if (op_pos == -1) | (op_pos == len(expr_arr)):\n","        print(\"something went wrong, operator should not be at end of array\")\n","    op = expr_arr[op_pos]\n","    if op in operators_inv.keys():\n","        num_args = operators_nargs[op]\n","        op = operators_inv[op]\n","        args = expr_arr[op_pos+1:op_pos+num_args+1]\n","        args = [parse_if_str(a) for a in args]\n","        func = op(*args)\n","        expr = expr_arr[0:op_pos] + [func] + expr_arr[op_pos+num_args+1:]\n","        return prefix_to_sympy(expr)\n","\n","    elif (op == 's+') | (op == \"s-\"):\n","        # int_end_pos = rightmost_int_pos(expr_arr)\n","        string_end_pos = rightmost_string_pos(expr_arr)\n","        integer = unformat_integer(expr_arr[op_pos:string_end_pos+1])\n","        expr_arr_new = expr_arr[0:op_pos] + [integer] + expr_arr[string_end_pos+1:]\n","        return prefix_to_sympy(expr_arr_new)\n","    elif op in variables:\n","        op = sp.sympify(op)\n","        expr_arr_new = expr_arr[0:op_pos] + [op] + expr_arr[op_pos+1:]\n","        return prefix_to_sympy(expr_arr_new)\n","\n","    return op"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.849288Z","iopub.status.busy":"2024-05-27T22:44:11.849024Z","iopub.status.idle":"2024-05-27T22:44:11.858105Z","shell.execute_reply":"2024-05-27T22:44:11.857041Z","shell.execute_reply.started":"2024-05-27T22:44:11.849257Z"},"trusted":true},"outputs":[],"source":["class DecoderTokenizer(Tokenizer):\n","    def __init__(self, vocab_path):\n","        super().__init__(vocab_path)\n","\n","    def equation_encoder(self, data):\n","        return [sympy_to_prefix(expr) for expr in data]\n","    \n","    def equation_decoder(self, data):\n","        return [prefix_to_sympy(lst) for lst in data]\n","\n","    def pre_tokenize(self, data):\n","        return data\n","    \n","    def tokenize(self, data):\n","        out = self.pre_tokenize(data)\n","        out = self.equation_encoder(out)\n","        out = [['<bos>'] + i + ['<eos>'] for i in out]\n","        out = self.encode(out)\n","        return out\n","    \n","    def reverse_tokenize(self, data):\n","        out = self.decode(data)\n","        out = self.equation_decoder(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.859769Z","iopub.status.busy":"2024-05-27T22:44:11.859191Z","iopub.status.idle":"2024-05-27T22:44:11.870912Z","shell.execute_reply":"2024-05-27T22:44:11.870119Z","shell.execute_reply.started":"2024-05-27T22:44:11.859738Z"},"trusted":true},"outputs":[],"source":["INPUT_DIR = '/kaggle/input/gsoc-symba-task/Feynman_with_units/Feynman_with_units/'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.872383Z","iopub.status.busy":"2024-05-27T22:44:11.872116Z","iopub.status.idle":"2024-05-27T22:44:11.893771Z","shell.execute_reply":"2024-05-27T22:44:11.892956Z","shell.execute_reply.started":"2024-05-27T22:44:11.872360Z"},"trusted":true},"outputs":[],"source":["PAD_IDX = 0\n","\n","def prepare_dataset(config):\n","\n","    input_max_len = config.input_max_len\n","    df = pd.read_csv(config.df_path)\n","\n","    encoder_tokenizer = Encoder_tokeniser(2,1,100,config.encoder_vocab)\n","    decoder_tokenizer = DecoderTokenizer(config.decoder_vocab)\n","\n","    train_df = {\n","        \"filename\":[],\n","        \"data_num\":[], \n","        \"number\":[]\n","        }\n","    \n","    for (index, row) in tqdm(df.iterrows()):\n","        with open(INPUT_DIR + row['Filename']) as file:\n","            data = file.readlines()\n","        X = encoder_tokenizer.tokenize(data)\n","\n","        n_splits = X.shape[0] // input_max_len\n","        X = X[:n_splits*input_max_len]\n","        x_chunks = np.split(X, n_splits)\n","\n","        sub_dir = os.path.join(config.output_dir, row[\"Filename\"])\n","        os.makedirs(sub_dir, exist_ok=True)\n","        \n","        for (index, x) in enumerate(x_chunks):\n","            np.save(os.path.join(sub_dir, f\"{index}.npy\"), x)\n","\n","        train_df[\"filename\"].extend([row[\"Filename\"]]*n_splits)\n","        train_df[\"data_num\"].extend([i for i in range(n_splits)])\n","        train_df[\"number\"].extend([row[\"Number\"] for i in range(n_splits)])\n","\n","    train_df = pd.DataFrame(train_df)\n","\n","    equations_df = {\n","        \"filename\":[],\n","        \"Prefix_lists\":[],\n","        \"encoded\":[]\n","        }\n","    \n","    prefix_equations = np.zeros((100, 256)).astype(np.int32)\n","    for (index, row) in df.iterrows():\n","        equations_df[\"filename\"].append(row[\"Filename\"])\n","        prefix = eval(row[\"Prefix_lists\"])\n","        prefix = [\"<bos>\"] + prefix + [\"<eos>\"]\n","        equations_df[\"Prefix_lists\"].append(prefix)\n","        y = decoder_tokenizer.encode([prefix])[0]\n","        y = np.pad(y, (0, 256 - len(y)))\n","        prefix_equations[int(row[\"Number\"])-1, :] = y\n","        equations_df[\"encoded\"].append(y)\n","\n","    path = os.path.join(config.output_dir, \"prefix_equations.npy\")\n","    np.save(path, prefix_equations)\n","    equations_df = pd.DataFrame(equations_df)\n","\n","    return train_df, equations_df\n","\n","class FeynmanDataset(Dataset):\n","    def __init__(self, df, dataset_dir):\n","        super().__init__()\n","        self.df = df\n","        self.dataset_dir = dataset_dir\n","        self.prefix_equations = np.load(os.path.join(dataset_dir, \"prefix_equations.npy\"))\n","        # prefix_equations = []\n","\n","        prefix_equations = []\n","        for prefix in self.prefix_equations:\n","            prefix_equations.append(np.trim_zeros(prefix))\n","\n","        self.prefix_equations = prefix_equations\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self, idx):\n","        row = self.df.iloc[idx]\n","        path = os.path.join(os.path.join(self.dataset_dir, row['Filename']), f\"{row['data_num']}.npy\")\n","        x = np.load(path).astype(np.int32)\n","\n","        path = os.path.join(self.dataset_dir, f\"{row['Filename']}.npy\")\n","        y = self.prefix_equations[int(row['number']) - 1]\n","\n","        return (torch.Tensor(x).long(), torch.Tensor(y).long())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.895316Z","iopub.status.busy":"2024-05-27T22:44:11.894997Z","iopub.status.idle":"2024-05-27T22:44:11.908413Z","shell.execute_reply":"2024-05-27T22:44:11.907627Z","shell.execute_reply.started":"2024-05-27T22:44:11.895288Z"},"trusted":true},"outputs":[],"source":["\n","def get_datasets(df, input_df, dataset_dir):\n","    train_df, test_df = train_test_split(df, test_size=0.1,random_state = 42)\n","    train_equations = train_df['Filename'].tolist()\n","    test_equations = test_df['Filename'].tolist()\n","\n","    input_test_df = input_df[input_df['Filename'].isin(test_equations)]\n","    input_train_df = input_df[input_df['Filename'].isin(train_equations)]\n","\n","    input_train_df, input_val_df = train_test_split(input_train_df, test_size = 0.1, shuffle=True)\n","\n","    train_dataset = FeynmanDataset(input_train_df, dataset_dir)\n","    val_dataset = FeynmanDataset(input_val_df, dataset_dir)\n","    test_dataset = FeynmanDataset(input_test_df, dataset_dir)\n","\n","    datasets = {\n","        \"train\":train_dataset,\n","        \"test\":test_dataset,\n","        \"valid\":val_dataset\n","        }\n","\n","    return datasets\n","\n","def get_dataloaders(datasets, train_bs, test_bs):\n","    train_dataloader = DataLoader(datasets['train'], batch_size=train_bs,\n","                                  shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n","    val_dataloader = DataLoader(datasets['valid'], batch_size=test_bs,\n","                                  shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n","    test_dataloader = DataLoader(datasets['test'], batch_size=test_bs,\n","                                  shuffle=True, num_workers=2, pin_memory=True, collate_fn=collate_fn)\n","    \n","    dataloaders = {\n","        \"train\":train_dataloader,\n","        \"test\":test_dataloader,\n","        \"valid\":val_dataloader\n","        }\n","    \n","    return dataloaders\n","\n","def collate_fn(batch):\n","    src_batch, tgt_batch = [], []\n","    for (src_sample, tgt_sample) in batch:\n","        src_batch.append(src_sample)\n","        tgt_batch.append(tgt_sample)\n","        \n","    src_batch = pad_sequence(src_batch, padding_value=PAD_IDX, batch_first=True)\n","    tgt_batch = pad_sequence(tgt_batch, padding_value=PAD_IDX, batch_first=True)\n","    return src_batch, tgt_batch"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.910161Z","iopub.status.busy":"2024-05-27T22:44:11.909561Z","iopub.status.idle":"2024-05-27T22:44:11.920987Z","shell.execute_reply":"2024-05-27T22:44:11.920146Z","shell.execute_reply.started":"2024-05-27T22:44:11.910136Z"},"trusted":true},"outputs":[],"source":["class config:\n","    def __init__(self):\n","        self.input_max_len = 1000\n","        self.max_len = 11\n","        self.df_path = '/kaggle/input/gsoc-symba-task/FeynmanEquationsModified.csv'\n","        self.encoder_vocab = '/kaggle/input/gsoc-symba-task/encoder_vocab (1).txt'\n","        self.decoder_vocab = '/kaggle/input/gsoc-symba-task/decoder_vocab (2).txt'\n","        self.output_dir = '/kaggle/working/dataset_arrays'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:11.922474Z","iopub.status.busy":"2024-05-27T22:44:11.922118Z","iopub.status.idle":"2024-05-27T22:44:11.990466Z","shell.execute_reply":"2024-05-27T22:44:11.989671Z","shell.execute_reply.started":"2024-05-27T22:44:11.922407Z"},"trusted":true},"outputs":[],"source":["train_df = pd.read_csv('/kaggle/input/gsoc-dataset-arrays/train_df.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:12.002553Z","iopub.status.busy":"2024-05-27T22:44:12.002138Z","iopub.status.idle":"2024-05-27T22:44:12.014020Z","shell.execute_reply":"2024-05-27T22:44:12.013120Z","shell.execute_reply.started":"2024-05-27T22:44:12.002528Z"},"trusted":true},"outputs":[],"source":["train_df.rename(columns = {'filename':'Filename'}, inplace = True)\n","train_df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:44:12.015329Z","iopub.status.busy":"2024-05-27T22:44:12.015060Z","iopub.status.idle":"2024-05-27T22:44:12.246807Z","shell.execute_reply":"2024-05-27T22:44:12.246016Z","shell.execute_reply.started":"2024-05-27T22:44:12.015305Z"},"trusted":true},"outputs":[],"source":["datasets = get_datasets(df_target,train_df,'/kaggle/input/gsoc-dataset-arrays/dataset_arrays/')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:07.472188Z","iopub.status.busy":"2024-05-27T22:45:07.471805Z","iopub.status.idle":"2024-05-27T22:45:07.477413Z","shell.execute_reply":"2024-05-27T22:45:07.476353Z","shell.execute_reply.started":"2024-05-27T22:45:07.472161Z"},"trusted":true},"outputs":[],"source":["dataloaders = get_dataloaders(datasets,64,64)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:07.993910Z","iopub.status.busy":"2024-05-27T22:45:07.993214Z","iopub.status.idle":"2024-05-27T22:45:08.015752Z","shell.execute_reply":"2024-05-27T22:45:08.014730Z","shell.execute_reply.started":"2024-05-27T22:45:07.993879Z"},"trusted":true},"outputs":[],"source":["class TokenEmbedding(nn.Module):\n","    ''' helper Module to convert tensor of input indices into corresponding tensor of token embeddings'''\n","    \n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","\n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","\n","class PositionalEncoding(nn.Module):\n","    ''' helper Module that adds positional encoding to the token embedding to introduce a notion of word order.'''\n","    \n","    def __init__(self,\n","                 emb_size: int,\n","                 dropout: float,\n","                 maxlen: int = 5000):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2)* math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        self.pos_embedding = torch.zeros((maxlen, emb_size))\n","        self.pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        self.pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        self.pos_embedding = self.pos_embedding.unsqueeze(0)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer('pos_embedding_1', self.pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","#         print(token_embedding.shape)\n","        token_embedding = token_embedding.to('cuda:0')\n","        self.pos_embedding = self.pos_embedding.to('cuda:0')\n","        return self.dropout(token_embedding + self.pos_embedding[:, :token_embedding.size(1), :])\n","\n","    \n","class LinearPointEmbedder(nn.Module):\n","    def __init__(self, vocab_size: int, input_emb_size, emb_size, max_input_points,dropout =0.2):\n","        super().__init__()\n","        self.embedding = nn.Embedding(vocab_size, input_emb_size)\n","        self.emb_size = emb_size\n","        self.input_size = max_input_points*input_emb_size\n","        self.fc1 = nn.Linear(self.input_size, emb_size)\n","        self.fc2 = nn.Linear(emb_size, emb_size)\n","        self.activation = nn.ReLU()\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, tokens):\n","        out = self.embedding(tokens.long()) * math.sqrt(self.emb_size)\n","        bs, n = out.shape[0], out.shape[1]\n","        out = out.view(bs, n, -1)\n","        out = self.activation(self.fc1(out))\n","        out = self.dropout(out)\n","        out = self.fc2(out)\n","        return out\n","    \n","\n","class Model_seq2seq(nn.Module):\n","    '''Seq2Seq Network'''\n","    \n","    def __init__(self,\n","                 num_encoder_layers: int,\n","                 num_decoder_layers: int,\n","                 emb_size: int,\n","                 nhead: int,\n","                 src_vocab_size: int,\n","                 tgt_vocab_size: int,\n","                 input_emb_size: int,\n","                 max_input_points: int,\n","                 dim_feedforward: int = 512,\n","                 dropout: float = 0.1,):\n","        super(Model_seq2seq, self).__init__()\n","        self.transformer = Transformer(d_model=emb_size,\n","                                       nhead=nhead,\n","                                       num_encoder_layers=num_encoder_layers,\n","                                       num_decoder_layers=num_decoder_layers,\n","                                       dim_feedforward=dim_feedforward,\n","                                       dropout=dropout,\n","                                       batch_first=True)\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = LinearPointEmbedder(src_vocab_size, input_emb_size, emb_size, max_input_points)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(emb_size, dropout=dropout)\n","\n","    def forward(self,\n","                src: Tensor,\n","                trg: Tensor,\n","                src_mask: Tensor,\n","                tgt_mask: Tensor,\n","                src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor,\n","                memory_key_padding_mask: Tensor):\n","        src_emb = self.src_tok_emb(src)\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","\n","        outs = self.transformer(src_emb, tgt_emb, src_mask, tgt_mask, None,\n","                                src_padding_mask, tgt_padding_mask, memory_key_padding_mask)\n","        return self.generator(outs)\n","\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer.encoder(self.src_tok_emb(src), src_mask)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer.decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:08.052888Z","iopub.status.busy":"2024-05-27T22:45:08.052586Z","iopub.status.idle":"2024-05-27T22:45:08.065666Z","shell.execute_reply":"2024-05-27T22:45:08.064834Z","shell.execute_reply.started":"2024-05-27T22:45:08.052866Z"},"trusted":true},"outputs":[],"source":["class AverageMeter:\n","    \"\"\"\n","    Computes and stores the average and current value\n","    \"\"\"\n","\n","    def __init__(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","def seed_everything(seed: int):\n","    random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","\n","def generate_square_subsequent_mask(sz, device):\n","    mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n","    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","    return mask\n","\n","def create_mask(src, tgt, device):\n","    src_seq_len = src.shape[1]\n","    tgt_seq_len = tgt.shape[1]\n","\n","    tgt_mask = generate_square_subsequent_mask(tgt_seq_len, device)\n","    src_mask = torch.zeros((src_seq_len, src_seq_len), device=device).type(torch.bool)\n","\n","    src_padding_mask = (torch.zeros((src.shape[0], src_seq_len), device=device)).type(torch.bool)\n","    tgt_padding_mask = (tgt == PAD_IDX)\n","    return src_mask, tgt_mask, src_padding_mask, tgt_padding_mask\n","\n","def sequence_accuracy(y_pred, y_true):\n","\n","    count = 0\n","    total = len(y_pred)\n","    for (predicted_tokens, original_tokens) in zip(y_pred, y_true):\n","        original_tokens = original_tokens.tolist()\n","        predicted_tokens = predicted_tokens.tolist()\n","        if original_tokens == predicted_tokens:\n","            count = count+1\n","\n","    return count/total"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:08.123725Z","iopub.status.busy":"2024-05-27T22:45:08.123403Z","iopub.status.idle":"2024-05-27T22:45:08.170036Z","shell.execute_reply":"2024-05-27T22:45:08.169125Z","shell.execute_reply.started":"2024-05-27T22:45:08.123669Z"},"trusted":true},"outputs":[],"source":["class Trainer:\n","    \"\"\"\n","    Trainer class for training and evaluating a PyTorch model.\n","    \"\"\"\n","    def __init__(self, config, dataloaders):\n","        \"\"\"\n","        Initialize Trainer object.\n","\n","        Args:\n","        - config: Configuration object containing training parameters\n","        - dataloaders: Dictionary containing data loaders for train, validation, and test sets\n","        \"\"\"\n","        self.config = config\n","        self.device = torch.device(self.config.device)\n","        self.dataloaders = dataloaders\n","\n","        seed_everything(self.config.seed)\n","\n","        self.scaler = torch.cuda.amp.GradScaler()\n","        if self.config.use_half_precision:\n","            self.dtype = torch.float16\n","        else:\n","            self.dtype = torch.float32\n","\n","        # Initialize model, optimizer, scheduler, and criterion\n","        self.model = self.get_model()\n","        self.model.to(self.device)\n","        self.optimizer = self.get_optimizer()\n","        self.scheduler = self.get_scheduler()\n","        self.criterion = self.get_criterion()\n","\n","        # Initialize training-related variables\n","        self.current_epoch = 0\n","        self.best_accuracy = -1\n","        self.best_val_loss = 1e6\n","        self.train_loss_list = []\n","        self.valid_loss_list = []\n","        self.valid_accuracy_tok_list = []\n","\n","        # Create directory for saving logs\n","        self.logs_dir = os.path.join(self.config.root_dir, self.config.experiment_name)\n","        os.makedirs(self.logs_dir, exist_ok=True)\n","\n","    def get_model(self):\n","        \"\"\"\n","        Initialize and return the model based on the configuration.\n","        \"\"\"\n","        model = Model_seq2seq(num_encoder_layers=self.config.num_encoder_layers,\n","                          num_decoder_layers=self.config.num_decoder_layers,\n","                          emb_size=self.config.embedding_size,\n","                          nhead=self.config.nhead,\n","                          src_vocab_size=self.config.src_vocab_size,\n","                          tgt_vocab_size=self.config.tgt_vocab_size,\n","                          input_emb_size=self.config.input_emb_size,\n","                          max_input_points=self.config.max_input_points,\n","                          )\n","        \n","        return model\n","\n","    def get_optimizer(self):\n","        \"\"\"\n","        Initialize and return the optimizer based on the configuration.\n","        \"\"\"\n","        optimizer_parameters = self.model.parameters()\n","\n","        if self.config.optimizer_type == \"sgd\":\n","            optimizer = torch.optim.SGD(optimizer_parameters, lr=self.config.optimizer_lr, momentum=self.config.optimizer_momentum,)\n","        elif self.config.optimizer_type == \"adam\":\n","            optimizer = torch.optim.Adam(optimizer_parameters, lr=self.config.optimizer_lr, eps=1e-8, weight_decay=self.config.optimizer_weight_decay)\n","        elif self.config.optimizer_type == \"adamw\":\n","            optimizer = torch.optim.AdamW(optimizer_parameters, lr=self.config.optimizer_lr, eps=1e-8, weight_decay=self.config.optimizer_weight_decay)\n","        else:\n","            raise NotImplementedError\n","        \n","        return optimizer\n","    \n","    def get_scheduler(self):\n","        \"\"\"\n","        Initialize and return the learning rate scheduler based on the configuration.\n","        \"\"\"\n","        if self.config.scheduler_type == \"multi_step\":\n","            scheduler = torch.optim.lr_scheduler.MultiStepLR(self.optimizer, milestones=self.config.scheduler_milestones, gamma=self.config.scheduler_gamma)\n","        elif self.config.scheduler_type == \"reduce_lr_on_plateau\":\n","            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(self.optimizer, mode='min', patience=2)\n","        elif self.config.scheduler_type == \"cosine_annealing_warm_restart\":\n","            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self.optimizer, self.config.T_0, self.config.T_mult)\n","        elif self.config.scheduler_type == \"none\":\n","            scheduler = None\n","        else:\n","            raise NotImplementedError\n","        \n","        return scheduler\n","\n","    \n","    def get_criterion(self):\n","        \"\"\"\n","        Initialize and return the loss function based on the configuration.\n","        \"\"\"\n","        if self.config.criterion == \"cross_entropy\":\n","            criterion = torch.nn.CrossEntropyLoss()\n","        else:\n","            raise NotImplementedError\n","        \n","        return criterion\n","\n","    def train_one_epoch(self):\n","        \"\"\"\n","        Train the model for one epoch.\n","        \"\"\"\n","        self.model.train()\n","        pbar = tqdm(self.dataloaders['train'], total=len(self.dataloaders['train']))\n","        pbar.set_description(f\"[{self.current_epoch+1}/{self.config.epochs}] Train\")\n","        running_loss = AverageMeter()\n","        for src, tgt in pbar:\n","            src = src.to(self.device)\n","            tgt = tgt.to(self.device)\n","\n","            bs = src.size(0)\n","\n","            with torch.autocast(device_type='cuda', dtype=self.dtype):\n","                src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt[:, :-1], self.device)\n","                logits = self.model(src, tgt[:, :-1], src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n","                loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt[:, 1:].reshape(-1))\n","                \n","            running_loss.update(loss.item(), bs)\n","            pbar.set_postfix(loss=running_loss.avg)\n","            \n","            self.optimizer.zero_grad()\n","            self.scaler.scale(loss).backward()\n","\n","            if self.config.clip_grad_norm > 0:\n","                torch.nn.utils.clip_grad_norm_(self.model.parameters(), self.config.clip_grad_norm)\n","            self.scaler.step(self.optimizer)\n","            self.scaler.update()\n","\n","        return running_loss.avg\n","\n","    def evaluate(self, phase):\n","        \"\"\"\n","        Evaluate the model on validation or test data.\n","\n","        Args:\n","        - phase: Phase of evaluation, either \"valid\" or \"test\".\n","\n","        Returns:\n","        - Tuple containing average token accuracy and average loss.\n","        \"\"\"\n","        self.model.eval()\n","        \n","        pbar = tqdm(self.dataloaders[phase], total=len(self.dataloaders[phase]))\n","        pbar.set_description(f\"[{self.current_epoch+1}/{self.config.epochs}] {phase.capitalize()}\")\n","        running_loss = AverageMeter()\n","        running_acc_tok = AverageMeter()\n","        \n","        \n","        for src, tgt in pbar:\n","            src = src.to(self.device)\n","            tgt = tgt.to(self.device)\n","            bs = src.size(0)\n","            \n","            with torch.autocast(device_type='cuda', dtype=self.dtype):\n","                if self.config.model_name == \"seq2seq_transformer\":\n","                    with torch.no_grad():\n","                        src_mask, tgt_mask, src_padding_mask, tgt_padding_mask = create_mask(src, tgt[:, :-1], self.device)\n","                        logits = self.model(src, tgt[:, :-1], src_mask, tgt_mask, src_padding_mask, tgt_padding_mask, src_padding_mask)\n","                        loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt[:, 1:].reshape(-1))\n","                else:\n","                    with torch.no_grad():\n","                        logits = self.model(src, tgt[:, :-1])\n","                        loss = self.criterion(logits.reshape(-1, logits.shape[-1]), tgt[:, 1:].reshape(-1))\n","\n","            y_pred = torch.argmax(logits.reshape(-1, logits.shape[-1]), 1)\n","            correct = (y_pred == tgt[:, 1:].reshape(-1)).cpu().numpy().mean()\n","            \n","            running_loss.update(loss.item(), bs)\n","            running_acc_tok.update(correct, bs)\n","            \n","        return running_acc_tok.avg, running_loss.avg\n","\n","    def train(self):\n","        \"\"\"\n","        Main training loop.\n","        \"\"\"\n","        start_epoch = self.current_epoch\n","        for self.current_epoch in range(start_epoch, self.config.epochs):\n","            training_loss = self.train_one_epoch() \n","            valid_accuracy_tok, valid_loss = self.evaluate(\"valid\")\n","            \n","            self.train_loss_list.append(round(training_loss, 7))\n","            self.valid_loss_list.append(round(valid_loss, 7))\n","            self.valid_accuracy_tok_list.append(round(valid_accuracy_tok, 7))\n","            \n","            if self.scheduler == \"multi_step\":\n","                self.scheduler.step()\n","            elif self.scheduler == \"reduce_lr_on_plateau\":\n","                self.scheduler.step(valid_loss)\n","                \n","            if valid_loss<self.best_val_loss:\n","                self.best_val_loss = valid_loss\n","\n","            self.save_model(\"last_checkpoint.pth\")\n","\n","            if valid_accuracy_tok > self.best_accuracy:\n","                print(f\"==> Best Accuracy improved to {round(valid_accuracy_tok, 7)} from {self.best_accuracy}\")\n","                self.best_accuracy = round(valid_accuracy_tok, 7)\n","                self.save_model(\"best_checkpoint.pth\")\n","            \n","            self.log_results()\n","\n","        \n","    def save_model(self, file_name):\n","        \"\"\"\n","        Save model checkpoints.\n","        \"\"\"\n","        state_dict = self.model.state_dict()\n","        torch.save({\n","                \"epoch\": self.current_epoch + 1,\n","                \"state_dict\": state_dict,\n","                'optimizer': self.optimizer.state_dict(),\n","                \"train_loss_list\": self.train_loss_list,\n","                \"valid_loss_list\": self.valid_loss_list,\n","                \"valid_accuracy_tok_list\": self.valid_accuracy_tok_list,\n","            }, os.path.join(self.logs_dir, file_name))\n","\n","    def log_results(self):\n","        \"\"\"\n","        Log training results to a CSV file.\n","        \"\"\"\n","        data_list = [self.train_loss_list, self.valid_loss_list, self.valid_accuracy_tok_list]\n","        column_list = ['train_losses', 'valid_losses', 'token_valid_accuracy']\n","        \n","        df_data = np.array(data_list).T\n","        df = pd.DataFrame(df_data, columns=column_list)\n","        df.to_csv(os.path.join(self.logs_dir, \"logs.csv\"))\n","        \n","    def test_seq_acc(self):\n","        \"\"\"\n","        Evaluate model's sequence accuracy on test data.\n","        \"\"\"\n","        file = os.path.join(self.logs_dir, \"best_checkpoint.pth\")\n","        state_dict = torch.load(file, map_location=self.device)['state_dict']\n","        self.model.load_state_dict(state_dict)\n","        \n","        test_accuracy_tok, _ = self.evaluate(\"test\")\n","        \n","        predictor = Predictor(self.config)\n","        \n","        print(\"Calculating Sequence Accuracy for predictions (1 example per batch)\")\n","        pbar = tqdm(self.dataloaders[\"test\"], total=len(self.dataloaders[\"test\"]))\n","        pbar.set_description(f\"Test\")\n","        \n","        y_preds = []\n","        y_true = []\n","        for src, tgt in pbar:\n","            src = src.to(self.device)\n","            tgt = tgt.numpy()\n","            bs = src.size(0)\n","            y_pred = predictor.predict(src[0].unsqueeze(0)) #only one example from each batch\n","            y_preds.append(y_pred.cpu().numpy())\n","            y_true.append(np.trim_zeros(tgt[0]))\n","\n","        test_accuracy_seq = sequence_accuracy(y_true, y_preds)\n","        f= open(os.path.join(self.logs_dir, \"score.txt\"),\"w+\")\n","        f.write(f\"Token Accuracy = {(round(test_accuracy_tok, 7))}\\n\")\n","        f.write(f\"Sequence Accuracy = {(round(test_accuracy_seq, 7))}\\n\")\n","        f.close()\n","        print(f\"Test Accuracy: {round(test_accuracy_tok, 7)} | Valid Accuracy: {self.best_accuracy}\") \n","        print(f\"Test Sequence Accuracy: {test_accuracy_seq}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:08.172056Z","iopub.status.busy":"2024-05-27T22:45:08.171733Z","iopub.status.idle":"2024-05-27T22:45:08.189699Z","shell.execute_reply":"2024-05-27T22:45:08.188813Z","shell.execute_reply.started":"2024-05-27T22:45:08.172027Z"},"trusted":true},"outputs":[],"source":["BOS_IDX = 1\n","EOS_IDX = 58  #69\n","\n","class Predictor:\n","    \"\"\"\n","    Predictor class for generating predictions using a trained model.\n","    \"\"\"\n","    def __init__(self, config):\n","        \"\"\"\n","        Initialize Predictor object.\n","\n","        Args:\n","        - config: Configuration object containing model parameters\n","        \"\"\"\n","        self.config = config\n","        self.device = torch.device(self.config.device)\n","\n","        # Get the model\n","        self.model = self.get_model()\n","        self.model.to(self.device)\n","\n","        # Load the best checkpoint\n","        self.logs_dir = os.path.join(self.config.root_dir, self.config.experiment_name)\n","        path = os.path.join(self.logs_dir, \"best_checkpoint.pth\")\n","        self.model.load_state_dict(torch.load(path)[\"state_dict\"])\n","        \n","        # Set the model to evaluation mode\n","        self.model.eval()\n","        \n","    def get_model(self):\n","        model = Model_seq2seq(num_encoder_layers=self.config.num_encoder_layers,\n","                      num_decoder_layers=self.config.num_decoder_layers,\n","                      emb_size=self.config.embedding_size,\n","                      nhead=self.config.nhead,\n","                      src_vocab_size=self.config.src_vocab_size,\n","                      tgt_vocab_size=self.config.tgt_vocab_size,\n","                      input_emb_size=self.config.input_emb_size,\n","                      max_input_points=self.config.max_input_points,\n","                      )\n","        \n","        return model\n","    \n","    def generate_square_subsequent_mask(self, sz, device):\n","        mask = (torch.triu(torch.ones((sz, sz), device=device)) == 1).transpose(0, 1)\n","        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n","        return mask\n","    \n","    def greedy_decode(self, src, src_mask, max_len, start_symbol, src_padding_mask=None):\n","        src = src.to(self.device)\n","        src_mask = src_mask.to(self.device)\n","        src_padding_mask = src_padding_mask.to(self.device)\n","        dim = 1\n","\n","        memory = self.model.encode(src, src_mask)\n","        memory = memory.to(self.device)\n","        dim = 1\n","        ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(self.device)\n","        for i in range(max_len-1):\n","\n","            tgt_mask = (self.generate_square_subsequent_mask(ys.size(1), self.device).type(torch.bool)).to(self.device)\n","\n","            out = self.model.decode(ys, memory, tgt_mask)\n","            prob = self.model.generator(out[:, -1])\n","\n","            _, next_word = torch.max(prob, dim=1)\n","            next_word = next_word.item()\n","\n","            ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=dim)\n","            if next_word == EOS_IDX:\n","                break\n","\n","        return ys\n","\n","\n","    def predict(self, x):\n","        self.model.eval()\n","        src = x\n","        num_tokens = src.shape[1]\n","\n","        src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n","        src_padding_mask = torch.zeros(1, num_tokens).type(torch.bool)\n","        tgt_tokens = self.greedy_decode(src, src_mask, max_len=256, start_symbol=BOS_IDX, src_padding_mask=src_padding_mask).flatten()\n","\n","        return tgt_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:08.191946Z","iopub.status.busy":"2024-05-27T22:45:08.191622Z","iopub.status.idle":"2024-05-27T22:45:08.205967Z","shell.execute_reply":"2024-05-27T22:45:08.205112Z","shell.execute_reply.started":"2024-05-27T22:45:08.191923Z"},"trusted":true},"outputs":[],"source":["class Config:\n","    experiment_name: Optional[str] = \"default\"\n","    root_dir: Optional[str] = \"./\"\n","    device: Optional[str] = \"cuda:0\"\n","    save_at_epochs: Optional[list] = field(default_factory=list)\n","    debug: Optional[bool] = False\n","        \n","    #training parameters\n","    epochs: Optional[int] = 10\n","    seed: Optional[int] = 42\n","    use_half_precision: Optional[bool] = True\n","\n","    #data loader parameters\n","    train_shuffle: Optional[bool] = True\n","    test_shuffle: Optional[bool] = False\n","    training_batch_size: Optional[int] = 1024\n","    test_batch_size: Optional[int] = 2048\n","    num_workers: Optional[int] = 4\n","    pin_memory: Optional[bool] = True\n","        \n","    # scheduler parameters\n","    scheduler_type: Optional[str] = \"cosine_annealing_warm_restart\" # multi_step or none\n","    T_0: Optional[int] = 10\n","    T_mult: Optional[int] = 1\n","\n","    # optimizer parameters\n","    optimizer_type: Optional[str] = \"adam\" # sgd or adam\n","    optimizer_lr: Optional[float] = 0.0001   \n","    optimizer_momentum: Optional[float] = 0.9\n","    optimizer_weight_decay: Optional[float] = 0.0001\n","    optimizer_no_decay: Optional[list] = field(default_factory=list)\n","    clip_grad_norm: Optional[float] = -1\n","        \n","    # Model Parameters\n","    model_name: Optional[str] = \"seq2seq_transformer\"\n","#     model_name: Optional[str] = \"LongFormerEncoderDecoder\"\n","    embedding_size: Optional[int] = 64\n","    hidden_dim: Optional[int] = 64\n","    nhead: Optional[int] = 8\n","    num_encoder_layers: Optional[int] = 2\n","    num_decoder_layers: Optional[int] = 6\n","    dropout: Optional[int] = 0.2\n","    pretrain: Optional[bool] = False\n","    input_emb_size: Optional[int] = 64\n","    max_input_points: Optional[int] = 33\n","    src_vocab_size: Optional[int] = 1104\n","    tgt_vocab_size: Optional[int] = 59\n","\n","    # Criterion\n","    criterion: Optional[str] = \"cross_entropy\"\n","        \n","    def print_config(self):\n","        print(\"=\"*50+\"\\nConfig\\n\"+\"=\"*50)\n","        for field in fields(self):\n","            print(field.name.ljust(30), getattr(self, field.name))\n","        print(\"=\"*50)\n","\n","    def save(self, root_dir):\n","        path = root_dir + \"/config.txt\"\n","        with open(path, \"w\") as f:\n","            f.write(\"=\"*50+\"\\nConfig\\n\"+\"=\"*50 + \"\\n\")\n","            for field in fields(self):\n","                f.write(field.name.ljust(30) + \": \" + str(getattr(self, field.name)) + \"\\n\")\n","            f.write(\"=\"*50) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:08.207312Z","iopub.status.busy":"2024-05-27T22:45:08.206999Z","iopub.status.idle":"2024-05-27T22:45:08.217533Z","shell.execute_reply":"2024-05-27T22:45:08.216643Z","shell.execute_reply.started":"2024-05-27T22:45:08.207282Z"},"trusted":true},"outputs":[],"source":["config = Config"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-27T22:45:08.237243Z","iopub.status.busy":"2024-05-27T22:45:08.236606Z","iopub.status.idle":"2024-05-27T22:45:09.125392Z","shell.execute_reply":"2024-05-27T22:45:09.123684Z","shell.execute_reply.started":"2024-05-27T22:45:08.237220Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(config,dataloaders)\n","trainer.train()\n","trainer.test_seq_acc()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4660212,"sourceId":7928956,"sourceType":"datasetVersion"},{"datasetId":4655603,"sourceId":8503193,"sourceType":"datasetVersion"},{"datasetId":4610731,"sourceId":8530806,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
